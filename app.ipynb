{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380bf1ff",
   "metadata": {},
   "source": [
    "# Face Sonification Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e6fdd0",
   "metadata": {},
   "source": [
    "ISSUES:\n",
    "* if you launch a synth (s_new), it's going to take some time until it is up and running: instantiation of a synth is asynchronous\n",
    "    * we may lose some messages before the synth is ready to play\n",
    "    * we should:\n",
    "        * start the synths in advance (maybe paused)\n",
    "        * pause synths when they are not useful instead of stopping them\n",
    "* often, we have a video recorded with a frame rate and sensor data that has been recorded with another frame rate\n",
    "    * PyQtGraph\n",
    "    * schedule visual events in the time queue\n",
    "* augmentation of the video with custom plotting, e.g. yourself plotting markers instead of having them plotted by OpenFace\n",
    "    * discuss if and how\n",
    "\n",
    "* The timing problem that OpenFace has seems to be related with OpenCV. The tracked video sometimes is sligtly shorter than the original one and sometimes it is longer. It seems that OpenCV has some problems working with some of the codecs.\n",
    "    * ffmpeg -i video.file -r 30 -vcodec ffv1 -acodec pcm_s16le output_name\n",
    "        * in my case, this does not work\n",
    "    * ffmpeg -i video.file -r 30 -vcodec ffv1 output_name\n",
    "    * split video frames into images if the previous solution fails.\n",
    "        * ffmpeg\n",
    "\n",
    "* We can consider the idea of focusing on the AUs that OpenFace detects with good precision and maybe cut off some of the others. We can find this information in the OpenFace paper.\n",
    "* The smile seems to be in many context the most important source of information. We can consider the idea of designing sonifications to put this element in the foreground.\n",
    "* The event-based sonification for how I implemented can be confusing for the listener: events are triggered only when the intensity of the AU goes over some thresholds (i.e. 1, 2, 3, 4). This way, the events are able to provide some information on the dinamic behaviour of the sound, but it also means that if an expression stays in the same range for a long time, we don't really have a continuous feedback, as the sound fades out quickly. Another problem is that events are also triggered when the intensity pass from a high range to a lower range; even if this provides some feedback on the dynamic behaviour, it is counterintuitive, because the user would expect the event to be associated to the activation of an expression.\n",
    "* We can try to use envelope parameters to handle the fall down\n",
    "* We can try a more hybrid approach. Some AUs will be sonified using an event-based approach that will omit information relative to the intensity, so that one event for expression will be triggered, e.g. one blink is sonified as one drop: we ignore the information on the intensity of the blink; we can do this for many other expression that are not our primary focus. The most important expressions (e.g. the smile), will be sonified somehow continuously, so that the listener would be able to perceive their stationary behaviour as well.\n",
    "\n",
    "* We could think of a musical sonification when AUs are associated to tracks that would play well together. When an AU is present, the relative track is played. AUs that are incompatible can be mapped to tracks that don's sound well together.\n",
    "    * Rithmical structured tracks\n",
    "    * Ambient\n",
    "* Sonify the movements of the head and of the eyes. We can sonify the degree of variation to the standard direction, so that when e.g. the head is in a standard position, no sound is played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e61022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:28:00.039678Z",
     "start_time": "2021-11-25T18:27:51.515380Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "import panson as ps\n",
    "from panson import bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb9707",
   "metadata": {},
   "source": [
    "## OpenFace workaround\n",
    "It works, but...\n",
    "* we have a very long conversion phase\n",
    "* the feature extraction is much longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2140736",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir full\n",
    "!ffmpeg -i full.avi -f image2 full/video-frame%05d.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9597dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec -it openface build/bin/FeatureExtraction -out_dir files/processed -fdir files/full -aus -gaze -pose -tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83783b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is the maximum quality\n",
    "!ffmpeg -y -i full.avi -vcodec mpeg4 -q:v 0 -max_muxing_queue_size 2048 full-rigth-codecs.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbedcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -i full.avi -vcodec libx264 -preset slow -crf 22 -max_muxing_queue_size 2048 -an full-rigth-codecs.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -i full.avi -vcodec libx264 -preset slow -crf 0 -max_muxing_queue_size 2048 -an full-rigth-codecs.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05abdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -i full.avi -vcodec libx264 -preset veryslow -crf 0 -max_muxing_queue_size 2048 -an full-rigth-codecs.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054af7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -i full.avi -vcodec mpeg4 -q:v 1 -max_muxing_queue_size 2048 -an full-rigth-codecs.avi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e5419",
   "metadata": {},
   "source": [
    "## Container setup and video processing\n",
    "\n",
    "The following section assumes that OpenFace was installed using docker.\n",
    "\n",
    "As first step, run the container with the following command:\n",
    "* `docker run -it --rm --name openface --mount type=bind,source=/home/michele/Desktop/Thesis/media/files,target=/home/openface-build/files algebr/openface:latest`\n",
    "* Substitute /home/michele/Desktop/Thesis/media/files with the mounting point\n",
    "* The current working directory must contain a directory **files/**\n",
    "    * This directory is bound with the --mount option to the files/ directory present in the docker container\n",
    "    * This directory is shared between the file system of the host and the one of the container\n",
    "\n",
    "Now we can launch the OpenFace executables (present in the container) from outside the container environment with a command similar to the following:\n",
    "* `docker exec -it openface build/bin/FeatureExtraction -out_dir files/processed -f files/video.avi`\n",
    "* From python (this notebook) we can call the same process and read the results\n",
    "* Create the directory files/processed in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xhost +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742cbcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T17:01:41.759644Z",
     "start_time": "2021-11-16T17:00:08.512375Z"
    }
   },
   "outputs": [],
   "source": [
    "# name given to the container\n",
    "CONTAINER_NAME = 'openface'\n",
    "\n",
    "# base directory of the container\n",
    "CONTAINER_BASE_DIR = '/home/openface-build'\n",
    "# directory with executalbles in the container\n",
    "CONTAINER_BIN_DIR = os.path.join(CONTAINER_BASE_DIR, 'build/bin')\n",
    "\n",
    "FILE_DIR = '../media/files'\n",
    "OUT_DIR = os.path.join(FILE_DIR, 'processed')\n",
    "\n",
    "CONTAINER_FILE_DIR = os.path.join(CONTAINER_BASE_DIR, 'files')\n",
    "CONTAINER_OUT_DIR = os.path.join(CONTAINER_FILE_DIR, 'processed')\n",
    "\n",
    "CONTAINER_EXECUTABLE = os.path.join(CONTAINER_BIN_DIR, 'FeatureExtraction')\n",
    "\n",
    "def feature_extraction_offline(video_name):\n",
    "    \n",
    "    video_path = os.path.join(FILE_DIR, video_name)\n",
    "    \n",
    "    # the file must be in FILE_DIR\n",
    "    if not os.path.isfile(video_path):\n",
    "        raise FileNotFoundError(video_path)\n",
    "    \n",
    "    container_video_path = os.path.join(CONTAINER_FILE_DIR, video_name)\n",
    "    \n",
    "    command = [\n",
    "        'docker', 'exec', CONTAINER_NAME, CONTAINER_EXECUTABLE,\n",
    "        '-f', container_video_path,\n",
    "        '-out_dir', CONTAINER_OUT_DIR,\n",
    "        # features extracted\n",
    "        '-pose', '-gaze', '-aus',\n",
    "        # output tracked video\n",
    "        '-tracked'\n",
    "    ]\n",
    "    \n",
    "    # capture and combine stdout and stderr into one stream and set as text stream\n",
    "    proc = subprocess.Popen(command,stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "        \n",
    "    # poll process and show its output\n",
    "    while True:\n",
    "        output = proc.stdout.readline()\n",
    "        \n",
    "        if output:\n",
    "            print(output.strip())\n",
    "            \n",
    "        if proc.poll() is not None:\n",
    "            break\n",
    "    \n",
    "    return proc\n",
    "\n",
    "def feature_extraction_online(pipe='files/pipe'):\n",
    "    \n",
    "    command = [\n",
    "        'docker', 'exec', CONTAINER_NAME, CONTAINER_EXECUTABLE,\n",
    "        '-device', # use default device\n",
    "        '-pose', '-gaze', '-aus',\n",
    "        # '-tracked'\n",
    "        '-of', pipe\n",
    "    ]\n",
    "    \n",
    "    # capture and combine stdout and stderr into one stream and set as text stream\n",
    "    proc = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)    \n",
    "\n",
    "    print('Starting real-time analysis...')\n",
    "    print('Open the pipe from the read side to start the feature stream')\n",
    "    \n",
    "    return proc\n",
    "\n",
    "def kill_feature_extraction_online():\n",
    "    # !docker exec -it openface pkill FeatureExt\n",
    "    command = ['docker', 'exec', CONTAINER_NAME, 'pkill', 'FeatureExt']\n",
    "    subprocess.run(command)\n",
    "\n",
    "def read_openface_csv(csv_path):\n",
    "    return pd.read_csv(csv_path, sep=r',\\s*', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e02d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffmpeg_convert(in_file, out_file):\n",
    "    \n",
    "    # this was the original command that appeared in the notebook\n",
    "    # ffmpeg -y -i \"files/processed/phone.avi\" -c:v libx264 -preset slow -crf 22 -pix_fmt yuv420p -c:a libvo_aacenc -b:a 128k \"files/phone-processed.mp4\"\n",
    "    command = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', in_file,\n",
    "        '-c:v', 'libx264',\n",
    "        '-crf', '22',\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        '-c:a', 'libvo_aacenc',\n",
    "        '-b:a', '128k',\n",
    "        out_file\n",
    "    ]\n",
    "    \n",
    "    proc = subprocess.run(command, capture_output=True)\n",
    "    \n",
    "    return proc\n",
    "\n",
    "def ffmpeg_merge(video_file, audio_file, out_file):\n",
    "    \n",
    "    # ffmpeg -i files/phone-processed.mp4 -i score.wav  -c:v copy phone-processed-son.mp4 -y\n",
    "                \n",
    "    command = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', video_file,\n",
    "        '-i', audio_file,\n",
    "        '-map', '0:v',\n",
    "        '-map', '1:a',\n",
    "        '-c:v', 'copy',\n",
    "        out_file\n",
    "    ]\n",
    "    \n",
    "    proc = subprocess.run(command, capture_output=True)\n",
    "    \n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'full-rigth-codecs.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f356ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time feature_extraction_offline(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_convert(\"files/processed/phone.avi\", \"files/phone-processed.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c962c08",
   "metadata": {},
   "source": [
    "## Sonifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e803b",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547bd7f",
   "metadata": {},
   "source": [
    "Here we are using the current **develop** branch of sc3nb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fcec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:56:54.169321Z",
     "start_time": "2021-11-26T00:56:54.160802Z"
    }
   },
   "outputs": [],
   "source": [
    "import sc3nb as scn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e8ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:57:34.103220Z",
     "start_time": "2021-11-26T00:57:30.546086Z"
    }
   },
   "outputs": [],
   "source": [
    "# start scsynth\n",
    "sc = scn.startup()\n",
    "# connect scsynth to the system playback\n",
    "!jack_connect \"SuperCollider:out_1\" \"system:playback_1\"\n",
    "!jack_connect \"SuperCollider:out_2\" \"system:playback_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d8053",
   "metadata": {},
   "source": [
    "If this does not work, open QJackCtl and link the nodes in the graph manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d52a89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:57:06.929914Z",
     "start_time": "2021-11-26T00:57:06.499795Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373d782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:57:56.377482Z",
     "start_time": "2021-11-26T00:57:56.355915Z"
    }
   },
   "outputs": [],
   "source": [
    "# test sound output\n",
    "sc.server.blip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.server.latency = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f1a1c",
   "metadata": {},
   "source": [
    "### Sonification 1: AU04 Test\n",
    "This is a very simple sonification of AU04 (Brow Lowerer). The intensity of AU04 is used here to modulate both the amplitude and the frequency of a continuous synth. As continuous synth, the default synth of sc3nb s2 is used (we will have to instruct the server to load it).\n",
    "\n",
    "* The intensity range \\[0,1\\] is mapped into the amplitude range \\[0,0.3\\], where 0.3 will be the maximum amplitude of the sound. The sonification has a parameter amp that can be used to scale this range.\n",
    "* The intensity range \\[0,5\\] is mapped into the midi range \\[69,81\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a (implicit ID allocation)\n",
    "class AU04ContinuousSonification(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.SliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.amp = 1\n",
    "    \n",
    "    @bundle\n",
    "    def _initialize(self):\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def _start(self):\n",
    "        self.synth = scn.Synth(\"s2\", {\"amp\": 0})\n",
    "    \n",
    "    @bundle\n",
    "    def _stop(self):\n",
    "        self._s.free_all()\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        self.synth.set(\n",
    "            # only \"max\" should be enough (to clip the top part to 0.3)\n",
    "            \"amp\", self.amp * scn.linlin(row[\"AU04_r\"], 0, 1, 0, 0.3, \"minmax\"),\n",
    "            # map the intensity of the AU in one octave range\n",
    "            \"freq\", scn.midicps(scn.linlin(row[\"AU04_r\"], 0, 5, 69, 81))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323abc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = AU04ContinuousSonification()\n",
    "son"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7269a",
   "metadata": {},
   "source": [
    "#### Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4138e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(OUT_DIR, \"phone.csv\"), sep=r',\\s*', engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay(['AU04_r', 'AU12_r'], queue_size=50)\n",
    "dp = ps.DataPlayer(son, feature_display=feature_display).load(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489019e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_display.show(fps=30)\n",
    "display(son)\n",
    "display(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c71e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c3fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp.export(\"score.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a7d5f",
   "metadata": {},
   "source": [
    "#### Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "FIFO = os.path.join(FILE_DIR, 'pipe.csv')\n",
    "\n",
    "def data_generator():\n",
    "    with open(FIFO, 'r') as fifo:\n",
    "        # the reader attempts to execute fifo.readline()\n",
    "        # which blocks if there are no lines\n",
    "        reader = csv.reader(fifo, skipinitialspace=True)\n",
    "        \n",
    "        header = next(reader)\n",
    "        \n",
    "        # the loop ends when the pipe is closed from the writing side\n",
    "        for i, row in enumerate(reader):\n",
    "            series = pd.Series(row, header, dtype='float', name=i)\n",
    "            yield series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay(['AU04_r', 'AU12_r'], 80)\n",
    "\n",
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb73c75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_display.show(fps=20)\n",
    "display(son)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380573d",
   "metadata": {},
   "source": [
    "### Sonification 2: Pentatonic eyes + brows\n",
    "* 1: Inner Brow Raiser\n",
    "* 2: Outer Brow Raiser (unilateral)\n",
    "* 4: Brow Lowerer\n",
    "* 5: Upper Lid Raiser\n",
    "* 6: Cheek Raiser\n",
    "* 7: Lid Tightener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92995e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PentatonicContinuous(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.SliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    BASE_TONE = 69\n",
    "    PENTATONIC = [\n",
    "        scn.midicps(BASE_TONE),\n",
    "        scn.midicps(BASE_TONE + 3),\n",
    "        scn.midicps(BASE_TONE + 5),\n",
    "        scn.midicps(BASE_TONE + 7),\n",
    "        scn.midicps(BASE_TONE + 10),\n",
    "        scn.midicps(BASE_TONE + 12)\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # parameters default\n",
    "        self.amp = 1\n",
    "    \n",
    "    @bundle\n",
    "    def _initialize(self):\n",
    "        # load default synth s2\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def _start(self):\n",
    "        self.au01_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[5]})\n",
    "        self.au02_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[4]})\n",
    "        self.au04_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[3]})\n",
    "        self.au05_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[2]})\n",
    "        self.au06_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[0]})\n",
    "        self.au07_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[1]})\n",
    "    \n",
    "    @bundle\n",
    "    def _stop(self):\n",
    "        self._s.free_all()\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        intensity = row[\"AU01_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au01_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU02_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au02_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU04_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au04_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU05_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au05_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU06_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au06_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU07_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au07_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "    @staticmethod\n",
    "    def map_intensity(intensity):\n",
    "        if intensity < 1.0:\n",
    "            amp = 0\n",
    "        else:\n",
    "            db = scn.linlin(intensity, 1, 5, -20, -5, \"minmax\")\n",
    "            amp = scn.dbamp(db)\n",
    "\n",
    "        return amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f706fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = PentatonicContinuous()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66df491",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = [\"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU07_r\"]\n",
    "feature_display = ps.LiveFeatureDisplay(interesting_features, 80)\n",
    "\n",
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display.show(fps=10)\n",
    "display(son)\n",
    "display(rtdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffe905",
   "metadata": {},
   "source": [
    "### Sonification 3: Pentatonic eyes + brows with MdaPiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869eeac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PentatonicMda(ps.Sonification):\n",
    "    \n",
    "    BASE_TONE = 69\n",
    "    PENTATONIC = [\n",
    "        scn.midicps(BASE_TONE),\n",
    "        scn.midicps(BASE_TONE + 3),\n",
    "        scn.midicps(BASE_TONE + 5),\n",
    "        scn.midicps(BASE_TONE + 7),\n",
    "        scn.midicps(BASE_TONE + 10),\n",
    "        scn.midicps(BASE_TONE + 12)\n",
    "    ]\n",
    "    \n",
    "    piano_def = scn.SynthDef(\n",
    "        \"mdapiano\",\n",
    "        r\"\"\"{ |freq=440, gate=1, vel=100, amp=1|\n",
    "            var piano = MdaPiano.ar(\n",
    "                freq,\n",
    "                gate,\n",
    "                vel,\n",
    "                decay: 0,\n",
    "                release: 0,\n",
    "                hard: 0,\n",
    "                stereo: 0,\n",
    "                sustain: 0,\n",
    "                mul: amp\n",
    "            );\n",
    "            DetectSilence.ar(piano, 0.01, doneAction:2);\n",
    "            Out.ar(0, piano);\n",
    "        }\"\"\"\n",
    "    )\n",
    "    \n",
    "    @bundle\n",
    "    def _initialize(self):\n",
    "        self.piano_def.add()\n",
    "\n",
    "    @bundle\n",
    "    def _start(self):\n",
    "        self.old_range_level_01 = 0\n",
    "        self.old_range_level_02 = 0\n",
    "        self.old_range_level_04 = 0\n",
    "        self.old_range_level_05 = 0\n",
    "        self.old_range_level_06 = 0\n",
    "        self.old_range_level_07 = 0\n",
    "        self.old_range_level_09 = 0\n",
    "        self.old_range_level_10 = 0\n",
    "        self.old_range_level_12 = 0\n",
    "        self.old_range_level_14 = 0\n",
    "        self.old_range_level_15 = 0\n",
    "        self.old_range_level_17 = 0\n",
    "        self.old_range_level_20 = 0\n",
    "        self.old_range_level_23 = 0\n",
    "        self.old_range_level_25 = 0\n",
    "        self.old_range_level_26 = 0\n",
    "    \n",
    "    @bundle\n",
    "    def _stop(self):\n",
    "        pass\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        intensity = row[\"AU01_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_01, cur_range_level, self.PENTATONIC[5])\n",
    "        self.old_range_level_01 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU02_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_02, cur_range_level, self.PENTATONIC[4])\n",
    "        self.old_range_level_02 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU04_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_04, cur_range_level, self.PENTATONIC[3])\n",
    "        self.old_range_level_04 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU05_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_05, cur_range_level, self.PENTATONIC[2])\n",
    "        self.old_range_level_05 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU06_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_06, cur_range_level, self.PENTATONIC[0])\n",
    "        self.old_range_level_06 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU07_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_07, cur_range_level, self.PENTATONIC[1])\n",
    "        self.old_range_level_07 = cur_range_level        \n",
    "        \n",
    "    @staticmethod\n",
    "    def map_range(old_range_level, cur_range_level, freq):\n",
    "        if cur_range_level != old_range_level and cur_range_level >= 1:\n",
    "            vel = scn.linlin(cur_range_level, 1, 5, 40, 127)\n",
    "            scn.Synth('mdapiano', {\"freq\": freq, \"vel\": vel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f518370",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = PentatonicMda()\n",
    "son"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a61636",
   "metadata": {},
   "source": [
    "TODO: adjust amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400898f7",
   "metadata": {},
   "source": [
    "### Sonification 4: Drop blink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1632604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlinkDrop(ps.Sonification):\n",
    "    \n",
    "    # drop definition\n",
    "    drop_def = scn.SynthDef(\n",
    "        \"drop\",\n",
    "        r\"\"\"{ | freq=600, dp=1200, amp=0.5, dur=0.1, pan=0 |\n",
    "            var sig, env, fch;\n",
    "            fch = XLine.kr(freq, freq+dp, dur);\n",
    "            sig = SinOsc.ar(fch);\n",
    "            env = EnvGen.kr(Env.perc(0.001, dur, curve: -4), 1.0, doneAction: 2);\n",
    "            Out.ar(0, Pan2.ar(sig, pan, env*amp))\n",
    "        }\"\"\"\n",
    "    )\n",
    "    \n",
    "    @bundle\n",
    "    def _initialize(self):\n",
    "        self.drop_def.add()\n",
    "\n",
    "    @bundle\n",
    "    def _start(self):\n",
    "        self.blinking = False\n",
    "    \n",
    "    @bundle\n",
    "    def _stop(self):\n",
    "        # drops die out alone\n",
    "        pass\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        intensity = row[\"AU45_r\"]\n",
    "        \n",
    "        if self.blinking:\n",
    "            if intensity < 1:\n",
    "                self.blinking = False\n",
    "        elif intensity >= 1:\n",
    "            self.blinking = True\n",
    "            scn.Synth(\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = BlinkDrop()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay([\"AU45_r\"], 80)\n",
    "\n",
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6635e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display.show(20)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2e991",
   "metadata": {},
   "source": [
    "### Sonification 5: Multi-percussion sound (event-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2847b11",
   "metadata": {},
   "source": [
    "Similar samples\n",
    "* snares\n",
    "<!--     * <audio controls src=\"samples/132417__sajmund__percussion-clave-like-hit.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/277397__earmark-audio__efev1-percussion-snare.wav\"/> -->\n",
    "* high bells\n",
    "<!--     * <audio controls src=\"samples/339808__inspectorj__hand-bells-c-db-single.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/360327__inspectorj__triangle-8-hard-hit-a.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/411574__inspectorj__alto-gong-metal-hit-b-h6-xy.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/387715__jagadamba__gong-percussion.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/414563__pjcohen__agogo-bell-low-velocity11.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/public domain/566514__ginijoyce__turning-objects-into-percussion-78.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/public domain/566386__ginijoyce__turning-objects-into-percussion-17.wav\"/> -->\n",
    "* crash\n",
    "<!--     * <audio controls src=\"samples/public domain/209874__veiler__pff-chrash-14.wav\"/> -->\n",
    "* electronic\n",
    "<!--     * <audio controls src=\"samples/public domain/487662__phonosupf__electronic-percussion-5.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/207919__altemark__space-snare.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/577014__nezuai__cartoon-percussion-3.wav\"/> -->\n",
    "* drums\n",
    "<!--     * <audio controls src=\"samples/public domain/439825__twentytwentymusic__electronic-percussion-2.wav\"/> -->\n",
    "    * <audio controls src=\"samples/public domain/439828__twentytwentymusic__electronic-percussion-6.wav\"/>\n",
    "<!--     * <audio controls src=\"samples/public domain/439829__twentytwentymusic__electronic-percussion-5.wav\"/> -->\n",
    "* bass drum\n",
    "<!--     * <audio controls src=\"samples/138358__minorr__bass-drum-p.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/234746__sonidotv__legno-10.wav\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2f509",
   "metadata": {},
   "source": [
    "Concepts:\n",
    "* Sounds that usually plays together should be distinguishable\n",
    "* Sounds that play more often should be less intrusive\n",
    "* One area should have sounds that are somehow related\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 1: Inner Brow Raiser - <audio controls src=\"samples/360327__inspectorj__triangle-8-hard-hit-a.wav\"/>\n",
    "* 2: Outer Brow Raiser (unilateral) - <audio controls src=\"samples/339808__inspectorj__hand-bells-c-db-single.wav\"/>\n",
    "* 4: Brow Lowerer - <audio controls src=\"samples/411574__inspectorj__alto-gong-metal-hit-b-h6-xy.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 5: Upper Lid Raiser - <audio controls src=\"samples/277397__earmark-audio__efev1-percussion-snare.wav\"/>\n",
    "* 6: Cheek Raiser - <audio controls src=\"samples/public domain/439829__twentytwentymusic__electronic-percussion-5.wav\"/>\n",
    "* 7: Lid Tightener - <audio controls src=\"samples/132417__sajmund__percussion-clave-like-hit.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 9: Nose Wrinkler (usually goes along with 4 and 10) - <audio controls src=\"samples/577014__nezuai__cartoon-percussion-3.wav\"/>\n",
    "* 10: Upper Lip Raiser - <audio controls src=\"samples/public domain/566386__ginijoyce__turning-objects-into-percussion-17.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 12: Lip Corner Puller - <audio controls src=\"samples/public domain/566514__ginijoyce__turning-objects-into-percussion-78.wav\"/>\n",
    "* 14: Dimpler - <audio controls src=\"samples/public domain/487662__phonosupf__electronic-percussion-5.wav\"/>\n",
    "* 15: Lip Corner Depressor - <audio controls src=\"samples/387715__jagadamba__gong-percussion.wav\"/>\n",
    "* 20: Lip Stretcher - <audio controls src=\"samples/414563__pjcohen__agogo-bell-low-velocity11.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 23: Lip Tightener - <audio controls src=\"samples/public domain/209874__veiler__pff-chrash-14.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 17: Chin Raiser - <audio controls src=\"samples/public domain/439825__twentytwentymusic__electronic-percussion-2.wav\"/>\n",
    "* 25: Lips Part (relax Mentalis, antagonist of AU17) - <audio controls src=\"samples/138358__minorr__bass-drum-p.wav\"/>\n",
    "* 26: Jaw Drop (usually goes along with 25) - <audio controls src=\"samples/234746__sonidotv__legno-10.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 28: Lip Suck (usually along with 26) - <audio controls src=\"samples/207919__altemark__space-snare.wav\"/>\n",
    "    * OpenFace only provides presence information\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 45: Blink (drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AU01_SAMPLE_PATH = \"samples/360327__inspectorj__triangle-8-hard-hit-a.wav\"\n",
    "AU02_SAMPLE_PATH = \"samples/339808__inspectorj__hand-bells-c-db-single.wav\"\n",
    "AU04_SAMPLE_PATH = \"samples/411574__inspectorj__alto-gong-metal-hit-b-h6-xy.wav\"\n",
    "AU05_SAMPLE_PATH = \"samples/277397__earmark-audio__efev1-percussion-snare.wav\"\n",
    "AU06_SAMPLE_PATH = \"samples/public domain/439829__twentytwentymusic__electronic-percussion-5.wav\"\n",
    "AU07_SAMPLE_PATH = \"samples/132417__sajmund__percussion-clave-like-hit.wav\"\n",
    "AU09_SAMPLE_PATH = \"samples/577014__nezuai__cartoon-percussion-3.wav\"\n",
    "AU10_SAMPLE_PATH = \"samples/public domain/566386__ginijoyce__turning-objects-into-percussion-17.wav\"\n",
    "AU12_SAMPLE_PATH = \"samples/public domain/566514__ginijoyce__turning-objects-into-percussion-78.wav\"\n",
    "AU14_SAMPLE_PATH = \"samples/public domain/487662__phonosupf__electronic-percussion-5.wav\"\n",
    "AU15_SAMPLE_PATH = \"samples/387715__jagadamba__gong-percussion.wav\"\n",
    "AU17_SAMPLE_PATH = \"samples/public domain/439825__twentytwentymusic__electronic-percussion-2.wav\"\n",
    "AU20_SAMPLE_PATH = \"samples/414563__pjcohen__agogo-bell-low-velocity11.wav\"\n",
    "AU23_SAMPLE_PATH = \"samples/public domain/209874__veiler__pff-chrash-14.wav\"\n",
    "AU25_SAMPLE_PATH = \"samples/138358__minorr__bass-drum-p.wav\"\n",
    "AU26_SAMPLE_PATH = \"samples/234746__sonidotv__legno-10.wav\"\n",
    "AU28_SAMPLE_PATH = \"samples/207919__altemark__space-snare.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49967b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Percussions(ps.Sonification):\n",
    "    \n",
    "    drop_def = scn.SynthDef(\n",
    "        \"drop\",\n",
    "        r\"\"\"{ | freq=600, dp=1200, amp=0.5, dur=0.1, pan=0 |\n",
    "            var sig, env, fch;\n",
    "            fch = XLine.kr(freq, freq+dp, dur);\n",
    "            sig = SinOsc.ar(fch);\n",
    "            env = EnvGen.kr(Env.perc(0.001, dur, curve: -4), 1.0, doneAction: 2);\n",
    "            Out.ar(0, Pan2.ar(sig, pan, env*amp))\n",
    "        }\"\"\"\n",
    "    )\n",
    "\n",
    "    # define custom playbuf synth that frees the synth when the buffer fades out\n",
    "    playbuf1_def = scn.SynthDef(\n",
    "        \"playbuf1\",\n",
    "        r\"\"\"{| out=0, bufnum=0, rate=1, amp=0.2, pan=0 |\n",
    "            var sig;\n",
    "            sig = PlayBuf.ar(1, bufnum, rate*BufRateScale.kr(bufnum), doneAction:2);\n",
    "            DetectSilence.ar(sig, 0.1, doneAction:2);\n",
    "            Out.ar(0, Pan2.ar(sig, pan, amp));\n",
    "        }\"\"\"\n",
    "    )\n",
    "\n",
    "    # Number of channels that the buffer will be. This must be a fixed integer. The architecture of the SynthDef cannot change after it is compiled.\n",
    "    playbuf2_def = scn.SynthDef(\n",
    "        \"playbuf2\",\n",
    "        r\"\"\"{| out=0, bufnum=0, rate=1, amp=0.2, pan=0 |\n",
    "            var sig;\n",
    "            sig = PlayBuf.ar(2, bufnum, rate*BufRateScale.kr(bufnum), doneAction:2);\n",
    "            DetectSilence.ar(sig, 0.1, doneAction:2);\n",
    "            Out.ar(0, Pan2.ar(sig, pan, amp));\n",
    "        }\"\"\"\n",
    "    )\n",
    "\n",
    "    @bundle\n",
    "    def _initialize(self):\n",
    "        self.drop_def.add()\n",
    "        self.playbuf1_def.add()\n",
    "        self.playbuf2_def.add()\n",
    "        \n",
    "        self.buf01 = scn.Buffer().read(AU01_SAMPLE_PATH)\n",
    "        self.buf02 = scn.Buffer().read(AU02_SAMPLE_PATH)\n",
    "        self.buf04 = scn.Buffer().read(AU04_SAMPLE_PATH)\n",
    "        self.buf05 = scn.Buffer().read(AU05_SAMPLE_PATH)\n",
    "        self.buf06 = scn.Buffer().read(AU06_SAMPLE_PATH)\n",
    "        self.buf07 = scn.Buffer().read(AU07_SAMPLE_PATH)\n",
    "        self.buf09 = scn.Buffer().read(AU09_SAMPLE_PATH)\n",
    "        self.buf10 = scn.Buffer().read(AU10_SAMPLE_PATH)\n",
    "        self.buf12 = scn.Buffer().read(AU12_SAMPLE_PATH)\n",
    "        self.buf14 = scn.Buffer().read(AU14_SAMPLE_PATH)\n",
    "        self.buf15 = scn.Buffer().read(AU15_SAMPLE_PATH)\n",
    "        self.buf17 = scn.Buffer().read(AU17_SAMPLE_PATH)\n",
    "        self.buf20 = scn.Buffer().read(AU20_SAMPLE_PATH)\n",
    "        self.buf23 = scn.Buffer().read(AU23_SAMPLE_PATH)\n",
    "        self.buf25 = scn.Buffer().read(AU25_SAMPLE_PATH)\n",
    "        self.buf26 = scn.Buffer().read(AU26_SAMPLE_PATH)\n",
    "        # self.buf28 = scn.Buffer().read(AU28_SAMPLE_PATH)\n",
    "\n",
    "    @bundle\n",
    "    def _start(self):\n",
    "        self.blinking = False\n",
    "        \n",
    "        self.old_range_level_01 = 0\n",
    "        self.old_range_level_02 = 0\n",
    "        self.old_range_level_04 = 0\n",
    "        self.old_range_level_05 = 0\n",
    "        self.old_range_level_06 = 0\n",
    "        self.old_range_level_07 = 0\n",
    "        self.old_range_level_09 = 0\n",
    "        self.old_range_level_10 = 0\n",
    "        self.old_range_level_12 = 0\n",
    "        self.old_range_level_14 = 0\n",
    "        self.old_range_level_15 = 0\n",
    "        self.old_range_level_17 = 0\n",
    "        self.old_range_level_20 = 0\n",
    "        self.old_range_level_23 = 0\n",
    "        self.old_range_level_25 = 0\n",
    "        self.old_range_level_26 = 0\n",
    "    \n",
    "    @bundle\n",
    "    def _stop(self):\n",
    "        # synths die out alone\n",
    "        pass\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        # cast intensity to integer\n",
    "        cur_range_level_01 = int(row[\"AU01_r\"])\n",
    "        self.map_range(self.old_range_level_01, cur_range_level_01, self.buf01)\n",
    "        # update old_range_level\n",
    "        self.old_range_level_01 = cur_range_level_01\n",
    "        \n",
    "        cur_range_level_02 = int(row[\"AU02_r\"])\n",
    "        self.map_range(self.old_range_level_02, cur_range_level_02, self.buf02)\n",
    "        self.old_range_level_02 = cur_range_level_02\n",
    "        \n",
    "        cur_range_level_04 = int(row[\"AU04_r\"])\n",
    "        self.map_range(self.old_range_level_04, cur_range_level_04, self.buf04)\n",
    "        self.old_range_level_04 = cur_range_level_04\n",
    "        \n",
    "        cur_range_level_05 = int(row[\"AU05_r\"])\n",
    "        self.map_range(self.old_range_level_05, cur_range_level_05, self.buf05)\n",
    "        self.old_range_level_05 = cur_range_level_05\n",
    "        \n",
    "        cur_range_level_06 = int(row[\"AU06_r\"])\n",
    "        self.map_range(self.old_range_level_06, cur_range_level_06, self.buf06)\n",
    "        self.old_range_level_06 = cur_range_level_06\n",
    "        \n",
    "        cur_range_level_07 = int(row[\"AU07_r\"])\n",
    "        self.map_range(self.old_range_level_07, cur_range_level_07, self.buf07)\n",
    "        self.old_range_level_07 = cur_range_level_07\n",
    "        \n",
    "        cur_range_level_09 = int(row[\"AU09_r\"])\n",
    "        self.map_range(self.old_range_level_09, cur_range_level_09, self.buf09)\n",
    "        self.old_range_level_09 = cur_range_level_09\n",
    "        \n",
    "        cur_range_level_10 = int(row[\"AU10_r\"])\n",
    "        self.map_range(self.old_range_level_10, cur_range_level_10, self.buf10)\n",
    "        self.old_range_level_10 = cur_range_level_10\n",
    "        \n",
    "        cur_range_level_12 = int(row[\"AU12_r\"])\n",
    "        self.map_range(self.old_range_level_12, cur_range_level_12, self.buf12)\n",
    "        self.old_range_level_12 = cur_range_level_12\n",
    "        \n",
    "        cur_range_level_14 = int(row[\"AU14_r\"])\n",
    "        self.map_range(self.old_range_level_14, cur_range_level_14, self.buf14)\n",
    "        self.old_range_level_14 = cur_range_level_14\n",
    "        \n",
    "        cur_range_level_15 = int(row[\"AU15_r\"])\n",
    "        self.map_range(self.old_range_level_15, cur_range_level_15, self.buf15)\n",
    "        self.old_range_level_15 = cur_range_level_15\n",
    "        \n",
    "        cur_range_level_17 = int(row[\"AU17_r\"])\n",
    "        self.map_range(self.old_range_level_17, cur_range_level_17, self.buf17)\n",
    "        self.old_range_level_17 = cur_range_level_17        \n",
    "        \n",
    "        cur_range_level_20 = int(row[\"AU20_r\"])\n",
    "        self.map_range(self.old_range_level_20, cur_range_level_20, self.buf20)\n",
    "        self.old_range_level_20 = cur_range_level_20\n",
    "        \n",
    "        cur_range_level_23 = int(row[\"AU23_r\"])\n",
    "        self.map_range(self.old_range_level_23, cur_range_level_23, self.buf23)\n",
    "        self.old_range_level_23 = cur_range_level_23\n",
    "        \n",
    "        cur_range_level_25 = int(row[\"AU25_r\"])\n",
    "        self.map_range(self.old_range_level_25, cur_range_level_25, self.buf25)\n",
    "        self.old_range_level_25 = cur_range_level_25\n",
    "        \n",
    "        cur_range_level_26 = int(row[\"AU26_r\"])\n",
    "        self.map_range(self.old_range_level_26, cur_range_level_26, self.buf26)\n",
    "        self.old_range_level_26 = cur_range_level_26\n",
    "        \n",
    "        intensity = row[\"AU45_r\"]\n",
    "        \n",
    "        if self.blinking:\n",
    "            if intensity < 1:\n",
    "                self.blinking = False\n",
    "        elif intensity >= 1:\n",
    "            self.blinking = True\n",
    "            scn.Synth(\"drop\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def map_range(old_range_level, cur_range_level, buf):\n",
    "\n",
    "        if cur_range_level != old_range_level and cur_range_level >= 1:\n",
    "            db = scn.linlin(cur_range_level, 1, 5, -20, 0, \"minmax\")\n",
    "            amp = scn.dbamp(db)\n",
    "\n",
    "            if buf.channels == 1:\n",
    "                synth = \"playbuf1\"\n",
    "            else:\n",
    "                synth = \"playbuf2\"\n",
    "\n",
    "            scn.Synth(synth, {\"bufnum\": buf.bufnum, \"amp\": amp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = Percussions()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20668d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face]",
   "language": "python",
   "name": "conda-env-face-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
