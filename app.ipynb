{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380bf1ff",
   "metadata": {},
   "source": [
    "# Face Sonification Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e6fdd0",
   "metadata": {},
   "source": [
    "ISSUES:\n",
    "* often, we have a video recorded with a frame rate and sensor data that has been recorded with another frame rate\n",
    "* augmentation of the video with custom plotting, e.g. yourself plotting markers instead of having them plotted by OpenFace\n",
    "    * discuss if and how\n",
    "    * PyQtGraph: pure-python graphics and GUI library built on PyQt / PySide and numpy\n",
    "* The **timing problem that OpenFace** has seems to be related with OpenCV. The tracked video sometimes is sligtly shorter than the original one and sometimes it is longer. It seems that OpenCV has some problems working with some of the codecs.\n",
    "    * ffmpeg -i video.file -r 30 -vcodec ffv1 -acodec pcm_s16le output_name\n",
    "        * in my case, this does not work\n",
    "    * ffmpeg -i video.file -r 30 -vcodec ffv1 output_name\n",
    "        * the audio codec should not be relevant\n",
    "    * split video frames into images if the previous solution fails\n",
    "        * ffmpeg\n",
    "        * we have to encode video info in the name of files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145dafd",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* record video demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e61022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:28:00.039678Z",
     "start_time": "2021-11-25T18:27:51.515380Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "import panson as ps\n",
    "from panson import bundle\n",
    "\n",
    "from math import pi, exp, log2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e5419",
   "metadata": {},
   "source": [
    "## Container setup and video processing\n",
    "\n",
    "The following section assumes that OpenFace was installed using docker.\n",
    "\n",
    "As first step, run the container with the following command:\n",
    "* `docker run -it --rm --name openface --mount type=bind,source=/home/michele/Desktop/Thesis/media/files,target=/home/openface-build/files algebr/openface:latest`\n",
    "* Substitute /home/michele/Desktop/Thesis/media/files with the mounting point\n",
    "* The current working directory must contain a directory **files/**\n",
    "    * This directory is bound with the --mount option to the files/ directory present in the docker container\n",
    "    * This directory is shared between the file system of the host and the one of the container\n",
    "\n",
    "Now we can launch the OpenFace executables (present in the container) from outside the container environment with a command similar to the following:\n",
    "* `docker exec -it openface build/bin/FeatureExtraction -out_dir files/processed -f files/video.avi`\n",
    "* From python (this notebook) we can call the same process and read the results\n",
    "* Create the directory files/processed in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xhost +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742cbcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T17:01:41.759644Z",
     "start_time": "2021-11-16T17:00:08.512375Z"
    }
   },
   "outputs": [],
   "source": [
    "# name given to the container\n",
    "CONTAINER_NAME = 'openface'\n",
    "\n",
    "# base directory of the container\n",
    "CONTAINER_BASE_DIR = '/home/openface-build'\n",
    "# directory with executalbles in the container\n",
    "CONTAINER_BIN_DIR = os.path.join(CONTAINER_BASE_DIR, 'build/bin')\n",
    "\n",
    "FILE_DIR = '../media/files'\n",
    "OUT_DIR = os.path.join(FILE_DIR, 'processed')\n",
    "\n",
    "CONTAINER_FILE_DIR = os.path.join(CONTAINER_BASE_DIR, 'files')\n",
    "CONTAINER_OUT_DIR = os.path.join(CONTAINER_FILE_DIR, 'processed')\n",
    "\n",
    "CONTAINER_EXECUTABLE = os.path.join(CONTAINER_BIN_DIR, 'FeatureExtraction')\n",
    "\n",
    "\n",
    "def feature_extraction_offline(video_name):\n",
    "    \n",
    "    video_path = os.path.join(FILE_DIR, video_name)\n",
    "    \n",
    "    # the file must be in FILE_DIR\n",
    "    if not os.path.isfile(video_path):\n",
    "        raise FileNotFoundError(video_path)\n",
    "    \n",
    "    container_video_path = os.path.join(CONTAINER_FILE_DIR, video_name)\n",
    "    \n",
    "    command = [\n",
    "        'docker', 'exec', CONTAINER_NAME, CONTAINER_EXECUTABLE,\n",
    "        '-f', container_video_path,\n",
    "        '-out_dir', CONTAINER_OUT_DIR,\n",
    "        # features extracted\n",
    "        '-pose', '-gaze', '-aus',\n",
    "        # output tracked video\n",
    "        '-tracked'\n",
    "    ]\n",
    "    \n",
    "    # capture and combine stdout and stderr into one stream and set as text stream\n",
    "    proc = subprocess.Popen(command,stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "        \n",
    "    # poll process and show its output\n",
    "    while True:\n",
    "        output = proc.stdout.readline()\n",
    "        \n",
    "        if output:\n",
    "            print(output.strip())\n",
    "            \n",
    "        if proc.poll() is not None:\n",
    "            break\n",
    "    \n",
    "    return proc\n",
    "\n",
    "def feature_extraction_online(pipe='files/pipe'):\n",
    "    \n",
    "    command = [\n",
    "        'docker', 'exec', CONTAINER_NAME, CONTAINER_EXECUTABLE,\n",
    "        '-device', '0', # use default device\n",
    "        '-pose', '-gaze', '-aus',\n",
    "        # '-tracked'\n",
    "        '-of', pipe\n",
    "    ]\n",
    "    \n",
    "    # capture and combine stdout and stderr into one stream and set as text stream\n",
    "    proc = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)    \n",
    "\n",
    "    print('Starting real-time analysis...')\n",
    "    print('Open the pipe from the read side to start the feature stream')\n",
    "    \n",
    "    return proc\n",
    "\n",
    "def kill_feature_extraction_online():\n",
    "    # !docker exec -it openface pkill FeatureExt\n",
    "    command = ['docker', 'exec', CONTAINER_NAME, 'pkill', 'FeatureExt']\n",
    "    subprocess.run(command)\n",
    "\n",
    "def read_openface_csv(csv_path):\n",
    "    return pd.read_csv(csv_path, sep=r',\\s*', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e02d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffmpeg_convert(in_file, out_file):\n",
    "    \n",
    "    # this was the original command that appeared in the notebook\n",
    "    # ffmpeg -y -i \"files/processed/phone.avi\" -c:v libx264 -preset slow -crf 22 -pix_fmt yuv420p -c:a libvo_aacenc -b:a 128k \"files/phone-processed.mp4\"\n",
    "    command = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', in_file,\n",
    "        '-c:v', 'libx264',\n",
    "        '-crf', '22',\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        '-c:a', 'libvo_aacenc',\n",
    "        '-b:a', '128k',\n",
    "        out_file\n",
    "    ]\n",
    "    \n",
    "    proc = subprocess.run(command, capture_output=True)\n",
    "    \n",
    "    return proc\n",
    "\n",
    "def ffmpeg_merge(video_file, audio_file, out_file):\n",
    "    \n",
    "    # ffmpeg -i files/phone-processed.mp4 -i score.wav  -c:v copy phone-processed-son.mp4 -y\n",
    "                \n",
    "    command = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', video_file,\n",
    "        '-i', audio_file,\n",
    "        '-map', '0:v',\n",
    "        '-map', '1:a',\n",
    "        '-c:v', 'copy',\n",
    "        out_file\n",
    "    ]\n",
    "    \n",
    "    proc = subprocess.run(command, capture_output=True)\n",
    "    \n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'full-rigth-codecs.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f356ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time feature_extraction_offline(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_convert(\"files/processed/phone.avi\", \"files/phone-processed.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c962c08",
   "metadata": {},
   "source": [
    "## Sonifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e803b",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b9f23",
   "metadata": {},
   "source": [
    "#### Supercollider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547bd7f",
   "metadata": {},
   "source": [
    "Here we are using the current **develop** branch of sc3nb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fcec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:56:54.169321Z",
     "start_time": "2021-11-26T00:56:54.160802Z"
    }
   },
   "outputs": [],
   "source": [
    "import sc3nb as scn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e8ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:57:34.103220Z",
     "start_time": "2021-11-26T00:57:30.546086Z"
    }
   },
   "outputs": [],
   "source": [
    "# start scsynth\n",
    "sc = scn.startup()\n",
    "# connect scsynth to the system playback\n",
    "!jack_connect \"SuperCollider:out_1\" \"system:playback_1\"\n",
    "!jack_connect \"SuperCollider:out_2\" \"system:playback_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d8053",
   "metadata": {},
   "source": [
    "If this does not work, open QJackCtl and link the nodes in the graph manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d52a89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:57:06.929914Z",
     "start_time": "2021-11-26T00:57:06.499795Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373d782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:57:56.377482Z",
     "start_time": "2021-11-26T00:57:56.355915Z"
    }
   },
   "outputs": [],
   "source": [
    "# test sound output\n",
    "sc.server.blip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.server.latency = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4dcfcc",
   "metadata": {},
   "source": [
    "#### Panson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bfe07c",
   "metadata": {},
   "source": [
    "##### Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(OUT_DIR, \"phone.csv\"), sep=r',\\s*', engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c16e0b",
   "metadata": {},
   "source": [
    "#### Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = None\n",
    "avg_features = df.filter(regex='(AU.{2}_r)|(pose_R.)|(gaze_angle_.)').columns.to_list()\n",
    "non_avg_features = None\n",
    "\n",
    "def init_moving_average():\n",
    "    global window, window_size\n",
    "    \n",
    "    window = pd.DataFrame()\n",
    "    window_size = 5\n",
    "    \n",
    "def moving_average(series):\n",
    "    global window\n",
    "    global features\n",
    "    global non_avg_features\n",
    "    \n",
    "    if features is None:\n",
    "        features = series.index.to_list()\n",
    "        non_avg_features = list(set(features) - set(avg_features))\n",
    "    \n",
    "    window = window.append(series[avg_features])\n",
    "    \n",
    "    if window.shape[0] > window_size:\n",
    "        window = window.drop(window.index[0])\n",
    "        \n",
    "    mean_series = window.mean()\n",
    "    \n",
    "    # fill other features\n",
    "    for feature in non_avg_features:\n",
    "        mean_series[feature] = series[feature]\n",
    "    \n",
    "    return mean_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "FIFO = os.path.join(FILE_DIR, 'pipe.csv')\n",
    "\n",
    "def data_generator(path=FIFO):\n",
    "    with open(path, 'r') as fifo:\n",
    "        # the reader attempts to execute fifo.readline()\n",
    "        # which blocks if there are no lines\n",
    "        reader = csv.reader(fifo, skipinitialspace=True)\n",
    "        \n",
    "        header = next(reader)\n",
    "        \n",
    "        # init_moving_average()\n",
    "        \n",
    "        # the loop ends when the pipe is closed from the writing side\n",
    "        for i, row in enumerate(reader):\n",
    "            series = pd.Series(row, header, dtype='float', name=i)\n",
    "            # series = moving_average(series)\n",
    "            yield series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f1a1c",
   "metadata": {},
   "source": [
    "### Sonification: AU04 Test\n",
    "This is a very simple sonification of AU04 (Brow Lowerer). The intensity of AU04 is used here to modulate both the amplitude and the frequency of a continuous synth. As continuous synth, the default synth of sc3nb s2 is used (we will have to instruct the server to load it).\n",
    "\n",
    "* The intensity range \\[0,1\\] is mapped into the amplitude range \\[0,0.3\\], where 0.3 will be the maximum amplitude of the sound. The sonification has a parameter amp that can be used to scale this range.\n",
    "* The intensity range \\[0,5\\] is mapped into the midi range \\[69,81\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a (implicit ID allocation)\n",
    "class AU04ContinuousSonification(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.amp = 1\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        # lag time is decided based on the frame rate\n",
    "        self.synth = scn.Synth(\"s2\", {\"amp\": 0, \"lg\": 0.03})\n",
    "\n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        self.synth.set(\n",
    "            # only \"max\" should be enough (to clip the top part to 0.3)\n",
    "            \"amp\", self.amp * scn.linlin(row[\"AU04_r\"], 0, 1, 0, 0.3, \"minmax\"),\n",
    "            # map the intensity of the AU in one octave range\n",
    "            \"freq\", scn.midicps(scn.linlin(row[\"AU04_r\"], 0, 5, 69, 81))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323abc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = AU04ContinuousSonification()\n",
    "son"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7269a",
   "metadata": {},
   "source": [
    "#### Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de0c54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay(['AU04_r', 'AU12_r'], queue_size=50)\n",
    "dp = ps.DataPlayer(son, feature_display=feature_display).load(df)\n",
    "\n",
    "# feature_display.show(fps=30)\n",
    "display(son)\n",
    "display(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c71e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c3fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp.export(\"score.wav\", header_format=\"WAV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a7d5f",
   "metadata": {},
   "source": [
    "#### Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay(['AU04_r', 'AU12_r'], 80)\n",
    "\n",
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb73c75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_display.show(fps=20)\n",
    "display(son)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380573d",
   "metadata": {},
   "source": [
    "### Sonification: Pentatonic eyes + brows\n",
    "* 1: Inner Brow Raiser\n",
    "* 2: Outer Brow Raiser (unilateral)\n",
    "* 4: Brow Lowerer\n",
    "* 5: Upper Lid Raiser\n",
    "* 6: Cheek Raiser\n",
    "* 7: Lid Tightener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92995e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PentatonicContinuous(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    BASE_TONE = 69\n",
    "    PENTATONIC = [\n",
    "        scn.midicps(BASE_TONE),\n",
    "        scn.midicps(BASE_TONE + 3),\n",
    "        scn.midicps(BASE_TONE + 5),\n",
    "        scn.midicps(BASE_TONE + 7),\n",
    "        scn.midicps(BASE_TONE + 10),\n",
    "        scn.midicps(BASE_TONE + 12)\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # parameters default\n",
    "        self.amp = 1\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        # load default synth s2\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.au01_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[5], \"lg\": 0.015})\n",
    "        self.au02_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[4], \"lg\": 0.015})\n",
    "        self.au04_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[3], \"lg\": 0.015})\n",
    "        self.au05_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[2], \"lg\": 0.015})\n",
    "        self.au06_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[0], \"lg\": 0.015})\n",
    "        self.au07_synth = scn.Synth(\"s2\", {\"amp\": 0, \"freq\": self.PENTATONIC[1], \"lg\": 0.015})\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        intensity = row[\"AU01_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au01_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU02_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au02_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU04_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au04_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU05_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au05_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU06_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au06_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "        intensity = row[\"AU07_r\"]\n",
    "        amp = self.map_intensity(intensity)\n",
    "        self.au07_synth.set(\"amp\", self.amp * amp)\n",
    "        \n",
    "    @staticmethod\n",
    "    def map_intensity(intensity):\n",
    "        if intensity < 1.0:\n",
    "            amp = 0\n",
    "        else:\n",
    "            db = scn.linlin(intensity, 1, 5, -20, -5, \"minmax\")\n",
    "            amp = scn.dbamp(db)\n",
    "\n",
    "        return amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f706fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = PentatonicContinuous()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66df491",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = [\"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU07_r\"]\n",
    "feature_display = ps.LiveFeatureDisplay(interesting_features, 80)\n",
    "\n",
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display.show(fps=10)\n",
    "display(son)\n",
    "display(rtdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffe905",
   "metadata": {},
   "source": [
    "### Sonification: Pentatonic eyes + brows with MdaPiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869eeac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PentatonicMda(ps.Sonification):\n",
    "    \n",
    "    BASE_TONE = 69\n",
    "    PENTATONIC = [\n",
    "        scn.midicps(BASE_TONE),\n",
    "        scn.midicps(BASE_TONE + 3),\n",
    "        scn.midicps(BASE_TONE + 5),\n",
    "        scn.midicps(BASE_TONE + 7),\n",
    "        scn.midicps(BASE_TONE + 10),\n",
    "        scn.midicps(BASE_TONE + 12)\n",
    "    ]\n",
    "    \n",
    "    piano_def = scn.SynthDef(\n",
    "        \"mdapiano\",\n",
    "        r\"\"\"{ |freq=440, gate=1, vel=100, amp=1|\n",
    "            var piano = MdaPiano.ar(\n",
    "                freq,\n",
    "                gate,\n",
    "                vel,\n",
    "                decay: 0,\n",
    "                release: 0,\n",
    "                hard: 0,\n",
    "                stereo: 0,\n",
    "                sustain: 0,\n",
    "                mul: amp\n",
    "            );\n",
    "            DetectSilence.ar(piano, 0.01, doneAction:2);\n",
    "            Out.ar(0, piano);\n",
    "        }\"\"\"\n",
    "    )\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        self.piano_def.add()\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.old_range_level_01 = 0\n",
    "        self.old_range_level_02 = 0\n",
    "        self.old_range_level_04 = 0\n",
    "        self.old_range_level_05 = 0\n",
    "        self.old_range_level_06 = 0\n",
    "        self.old_range_level_07 = 0\n",
    "        self.old_range_level_09 = 0\n",
    "        self.old_range_level_10 = 0\n",
    "        self.old_range_level_12 = 0\n",
    "        self.old_range_level_14 = 0\n",
    "        self.old_range_level_15 = 0\n",
    "        self.old_range_level_17 = 0\n",
    "        self.old_range_level_20 = 0\n",
    "        self.old_range_level_23 = 0\n",
    "        self.old_range_level_25 = 0\n",
    "        self.old_range_level_26 = 0\n",
    "    \n",
    "    @bundle\n",
    "    def stop(self):\n",
    "        pass\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        intensity = row[\"AU01_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_01, cur_range_level, self.PENTATONIC[5])\n",
    "        self.old_range_level_01 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU02_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_02, cur_range_level, self.PENTATONIC[4])\n",
    "        self.old_range_level_02 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU04_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_04, cur_range_level, self.PENTATONIC[3])\n",
    "        self.old_range_level_04 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU05_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_05, cur_range_level, self.PENTATONIC[2])\n",
    "        self.old_range_level_05 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU06_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_06, cur_range_level, self.PENTATONIC[0])\n",
    "        self.old_range_level_06 = cur_range_level\n",
    "        \n",
    "        intensity = row[\"AU07_r\"]\n",
    "        cur_range_level = int(intensity)\n",
    "        self.map_range(self.old_range_level_07, cur_range_level, self.PENTATONIC[1])\n",
    "        self.old_range_level_07 = cur_range_level        \n",
    "        \n",
    "    @staticmethod\n",
    "    def map_range(old_range_level, cur_range_level, freq):\n",
    "        if cur_range_level != old_range_level and cur_range_level >= 1:\n",
    "            vel = scn.linlin(cur_range_level, 1, 5, 40, 127)\n",
    "            scn.Synth('mdapiano', {\"freq\": freq, \"vel\": vel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f518370",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = PentatonicMda()\n",
    "son"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a61636",
   "metadata": {},
   "source": [
    "TODO: adjust amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400898f7",
   "metadata": {},
   "source": [
    "### Sonification: Drop blink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1632604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropBlink(ps.Sonification):\n",
    "    \n",
    "    # hysteresis boundaries\n",
    "    bounds = ps.FloatRangeSliderParameter(0, 5, 0.1)\n",
    "    \n",
    "    # drop definition\n",
    "    drop_def = scn.SynthDef(\n",
    "        \"drop\",\n",
    "        r\"\"\"{ | freq=600, dp=1200, amp=0.5, dur=0.1, pan=0 |\n",
    "            var sig, env, fch;\n",
    "            fch = XLine.kr(freq, freq+dp, dur);\n",
    "            sig = SinOsc.ar(fch);\n",
    "            env = EnvGen.kr(Env.perc(0.001, dur, curve: -4), 1.0, doneAction: 2);\n",
    "            Out.ar(0, Pan2.ar(sig, pan, env*amp))\n",
    "        }\"\"\"\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bounds = [1, 1.6]\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        self.drop_def.add()\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.blinking = False\n",
    "    \n",
    "    @bundle\n",
    "    def stop(self):\n",
    "        # drops die out alone\n",
    "        pass\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        intensity = row[\"AU45_r\"]\n",
    "        \n",
    "        if self.blinking:\n",
    "            if intensity < self.bounds[0]:\n",
    "                self.blinking = False\n",
    "        elif intensity > self.bounds[1]:\n",
    "            self.blinking = True\n",
    "            scn.Synth(\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = DropBlink()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay([\"AU45_r\"], 80)\n",
    "\n",
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display=feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6635e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display.show(10)\n",
    "display(son)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9338cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleDropBlink(DropBlink):\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        intensity = row[\"AU45_r\"]\n",
    "        \n",
    "        if self.blinking:\n",
    "            if intensity < self.bounds[0]:\n",
    "                self.blinking = False\n",
    "                scn.Synth(\"drop\", {\"freq\": 900})\n",
    "        elif intensity > self.bounds[1]:\n",
    "            self.blinking = True\n",
    "            scn.Synth(\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2e991",
   "metadata": {},
   "source": [
    "### Multi-percussion (event-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2847b11",
   "metadata": {},
   "source": [
    "Similar samples\n",
    "* snares\n",
    "<!--     * <audio controls src=\"samples/132417__sajmund__percussion-clave-like-hit.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/277397__earmark-audio__efev1-percussion-snare.wav\"/> -->\n",
    "* high bells\n",
    "<!--     * <audio controls src=\"samples/339808__inspectorj__hand-bells-c-db-single.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/360327__inspectorj__triangle-8-hard-hit-a.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/411574__inspectorj__alto-gong-metal-hit-b-h6-xy.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/387715__jagadamba__gong-percussion.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/414563__pjcohen__agogo-bell-low-velocity11.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/public domain/566514__ginijoyce__turning-objects-into-percussion-78.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/public domain/566386__ginijoyce__turning-objects-into-percussion-17.wav\"/> -->\n",
    "* crash\n",
    "<!--     * <audio controls src=\"samples/public domain/209874__veiler__pff-chrash-14.wav\"/> -->\n",
    "* electronic\n",
    "<!--     * <audio controls src=\"samples/public domain/487662__phonosupf__electronic-percussion-5.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/207919__altemark__space-snare.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/577014__nezuai__cartoon-percussion-3.wav\"/> -->\n",
    "* drums\n",
    "<!--     * <audio controls src=\"samples/public domain/439825__twentytwentymusic__electronic-percussion-2.wav\"/> -->\n",
    "    * <audio controls src=\"samples/public domain/439828__twentytwentymusic__electronic-percussion-6.wav\"/>\n",
    "<!--     * <audio controls src=\"samples/public domain/439829__twentytwentymusic__electronic-percussion-5.wav\"/> -->\n",
    "* bass drum\n",
    "<!--     * <audio controls src=\"samples/138358__minorr__bass-drum-p.wav\"/> -->\n",
    "<!--     * <audio controls src=\"samples/234746__sonidotv__legno-10.wav\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2f509",
   "metadata": {},
   "source": [
    "Concepts:\n",
    "* Sounds that usually plays together should be distinguishable\n",
    "* Sounds that play more often should be less intrusive\n",
    "* One area should have sounds that are somehow related\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 1: Inner Brow Raiser - <audio controls src=\"samples/modified/au01.wav\"/>\n",
    "* 2: Outer Brow Raiser (unilateral) - <audio controls src=\"samples/modified/au02.wav\"/>\n",
    "* 4: Brow Lowerer - <audio controls src=\"samples/modified/au04.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 5: Upper Lid Raiser - <audio controls src=\"samples/modified/au05.wav\"/>\n",
    "* 6: Cheek Raiser - <audio controls src=\"samples/modified/au06.wav\"/>\n",
    "* 7: Lid Tightener - <audio controls src=\"samples/modified/au07.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 9: Nose Wrinkler (usually goes along with 4 and 10) - <audio controls src=\"samples/modified/au09.wav\"/>\n",
    "* 10: Upper Lip Raiser - <audio controls src=\"samples/modified/au10.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 12: Lip Corner Puller - <audio controls src=\"samples/modified/au12.wav\"/>\n",
    "* 14: Dimpler - <audio controls src=\"samples/modified/au14.wav\"/>\n",
    "* 15: Lip Corner Depressor - <audio controls src=\"samples/modified/au15.wav\"/>\n",
    "* 20: Lip Stretcher - <audio controls src=\"samples/modified/au20.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 23: Lip Tightener - <audio controls src=\"samples/modified/au23.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 17: Chin Raiser - <audio controls src=\"samples/modified/au17.wav\"/>\n",
    "* 25: Lips Part (relax Mentalis, antagonist of AU17) - <audio controls src=\"samples/modified/au25.wav\"/>\n",
    "* 26: Jaw Drop (usually goes along with 25) - <audio controls src=\"samples/modified/au26.wav\"/>\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 28: Lip Suck (usually along with 26) - <audio controls src=\"samples/modified/au28.wav\"/>\n",
    "    * OpenFace only provides presence information\n",
    "\n",
    "<hr>\n",
    "\n",
    "* 45: Blink (drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AU01_SAMPLE_PATH = \"samples/modified/au01.wav\"\n",
    "AU02_SAMPLE_PATH = \"samples/modified/au02.wav\"\n",
    "AU04_SAMPLE_PATH = \"samples/modified/au04.wav\"\n",
    "AU05_SAMPLE_PATH = \"samples/modified/au05.wav\"\n",
    "AU06_SAMPLE_PATH = \"samples/modified/au06.wav\"\n",
    "AU07_SAMPLE_PATH = \"samples/modified/au07.wav\"\n",
    "AU09_SAMPLE_PATH = \"samples/modified/au09.wav\"\n",
    "AU10_SAMPLE_PATH = \"samples/modified/au10.wav\"\n",
    "AU12_SAMPLE_PATH = \"samples/modified/au12.wav\"\n",
    "AU14_SAMPLE_PATH = \"samples/modified/au14.wav\"\n",
    "AU15_SAMPLE_PATH = \"samples/modified/au15.wav\"\n",
    "AU17_SAMPLE_PATH = \"samples/modified/au17.wav\"\n",
    "AU20_SAMPLE_PATH = \"samples/modified/au20.wav\"\n",
    "AU23_SAMPLE_PATH = \"samples/modified/au23.wav\"\n",
    "AU25_SAMPLE_PATH = \"samples/modified/au25.wav\"\n",
    "AU26_SAMPLE_PATH = \"samples/modified/au26.wav\"\n",
    "AU28_SAMPLE_PATH = \"samples/modified/au28.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80afaf5",
   "metadata": {},
   "source": [
    "#### Sonification: Percussive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49967b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Percussive(ps.Sonification):\n",
    "\n",
    "    playbuf_def = scn.SynthDef(\n",
    "        \"playbuf\",\n",
    "        r\"\"\"{| out=0, bufnum=0, rate=1, amp=1, pan=0 |\n",
    "            var sig;\n",
    "            sig = PlayBuf.ar(1, bufnum, rate*BufRateScale.kr(bufnum), doneAction:2);\n",
    "            Out.ar(0, Pan2.ar(sig, pan, amp));\n",
    "        }\"\"\"\n",
    "    )\n",
    "\n",
    "    @bundle\n",
    "    def init(self):\n",
    "        self.playbuf_def.add()\n",
    "        \n",
    "        self.buf01 = scn.Buffer().read(AU01_SAMPLE_PATH)\n",
    "        self.buf02 = scn.Buffer().read(AU02_SAMPLE_PATH)\n",
    "        self.buf04 = scn.Buffer().read(AU04_SAMPLE_PATH)\n",
    "        self.buf05 = scn.Buffer().read(AU05_SAMPLE_PATH)\n",
    "        self.buf06 = scn.Buffer().read(AU06_SAMPLE_PATH)\n",
    "        self.buf07 = scn.Buffer().read(AU07_SAMPLE_PATH)\n",
    "        self.buf09 = scn.Buffer().read(AU09_SAMPLE_PATH)\n",
    "        self.buf10 = scn.Buffer().read(AU10_SAMPLE_PATH)\n",
    "        self.buf12 = scn.Buffer().read(AU12_SAMPLE_PATH)\n",
    "        self.buf14 = scn.Buffer().read(AU14_SAMPLE_PATH)\n",
    "        self.buf15 = scn.Buffer().read(AU15_SAMPLE_PATH)\n",
    "        self.buf17 = scn.Buffer().read(AU17_SAMPLE_PATH)\n",
    "        self.buf20 = scn.Buffer().read(AU20_SAMPLE_PATH)\n",
    "        self.buf23 = scn.Buffer().read(AU23_SAMPLE_PATH)\n",
    "        self.buf25 = scn.Buffer().read(AU25_SAMPLE_PATH)\n",
    "        self.buf26 = scn.Buffer().read(AU26_SAMPLE_PATH)\n",
    "        # self.buf28 = scn.Buffer().read(AU28_SAMPLE_PATH)\n",
    "\n",
    "    @bundle\n",
    "    def start(self):        \n",
    "        self.old_range_level_01 = 0\n",
    "        self.old_range_level_02 = 0\n",
    "        self.old_range_level_04 = 0\n",
    "        self.old_range_level_05 = 0\n",
    "        self.old_range_level_06 = 0\n",
    "        self.old_range_level_07 = 0\n",
    "        self.old_range_level_09 = 0\n",
    "        self.old_range_level_10 = 0\n",
    "        self.old_range_level_12 = 0\n",
    "        self.old_range_level_14 = 0\n",
    "        self.old_range_level_15 = 0\n",
    "        self.old_range_level_17 = 0\n",
    "        self.old_range_level_20 = 0\n",
    "        self.old_range_level_23 = 0\n",
    "        self.old_range_level_25 = 0\n",
    "        self.old_range_level_26 = 0\n",
    "    \n",
    "    @bundle\n",
    "    def stop(self):\n",
    "        # synths die out alone\n",
    "        pass\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        # cast intensity to integer\n",
    "        cur_range_level_01 = int(row[\"AU01_r\"])\n",
    "        self.map_range(self.old_range_level_01, cur_range_level_01, self.buf01)\n",
    "        # update old_range_level\n",
    "        self.old_range_level_01 = cur_range_level_01\n",
    "        \n",
    "        cur_range_level_02 = int(row[\"AU02_r\"])\n",
    "        self.map_range(self.old_range_level_02, cur_range_level_02, self.buf02)\n",
    "        self.old_range_level_02 = cur_range_level_02\n",
    "        \n",
    "        cur_range_level_04 = int(row[\"AU04_r\"])\n",
    "        self.map_range(self.old_range_level_04, cur_range_level_04, self.buf04)\n",
    "        self.old_range_level_04 = cur_range_level_04\n",
    "        \n",
    "        cur_range_level_05 = int(row[\"AU05_r\"])\n",
    "        self.map_range(self.old_range_level_05, cur_range_level_05, self.buf05)\n",
    "        self.old_range_level_05 = cur_range_level_05\n",
    "        \n",
    "        cur_range_level_06 = int(row[\"AU06_r\"])\n",
    "        self.map_range(self.old_range_level_06, cur_range_level_06, self.buf06)\n",
    "        self.old_range_level_06 = cur_range_level_06\n",
    "        \n",
    "        cur_range_level_07 = int(row[\"AU07_r\"])\n",
    "        self.map_range(self.old_range_level_07, cur_range_level_07, self.buf07)\n",
    "        self.old_range_level_07 = cur_range_level_07\n",
    "        \n",
    "        cur_range_level_09 = int(row[\"AU09_r\"])\n",
    "        self.map_range(self.old_range_level_09, cur_range_level_09, self.buf09)\n",
    "        self.old_range_level_09 = cur_range_level_09\n",
    "        \n",
    "        cur_range_level_10 = int(row[\"AU10_r\"])\n",
    "        self.map_range(self.old_range_level_10, cur_range_level_10, self.buf10)\n",
    "        self.old_range_level_10 = cur_range_level_10\n",
    "        \n",
    "        cur_range_level_12 = int(row[\"AU12_r\"])\n",
    "        self.map_range(self.old_range_level_12, cur_range_level_12, self.buf12)\n",
    "        self.old_range_level_12 = cur_range_level_12\n",
    "        \n",
    "        cur_range_level_14 = int(row[\"AU14_r\"])\n",
    "        self.map_range(self.old_range_level_14, cur_range_level_14, self.buf14)\n",
    "        self.old_range_level_14 = cur_range_level_14\n",
    "        \n",
    "        cur_range_level_15 = int(row[\"AU15_r\"])\n",
    "        self.map_range(self.old_range_level_15, cur_range_level_15, self.buf15)\n",
    "        self.old_range_level_15 = cur_range_level_15\n",
    "        \n",
    "        cur_range_level_17 = int(row[\"AU17_r\"])\n",
    "        self.map_range(self.old_range_level_17, cur_range_level_17, self.buf17)\n",
    "        self.old_range_level_17 = cur_range_level_17        \n",
    "        \n",
    "        cur_range_level_20 = int(row[\"AU20_r\"])\n",
    "        self.map_range(self.old_range_level_20, cur_range_level_20, self.buf20)\n",
    "        self.old_range_level_20 = cur_range_level_20\n",
    "        \n",
    "        cur_range_level_23 = int(row[\"AU23_r\"])\n",
    "        self.map_range(self.old_range_level_23, cur_range_level_23, self.buf23)\n",
    "        self.old_range_level_23 = cur_range_level_23\n",
    "        \n",
    "        cur_range_level_25 = int(row[\"AU25_r\"])\n",
    "        self.map_range(self.old_range_level_25, cur_range_level_25, self.buf25)\n",
    "        self.old_range_level_25 = cur_range_level_25\n",
    "        \n",
    "        cur_range_level_26 = int(row[\"AU26_r\"])\n",
    "        self.map_range(self.old_range_level_26, cur_range_level_26, self.buf26)\n",
    "        self.old_range_level_26 = cur_range_level_26\n",
    "\n",
    "    @staticmethod\n",
    "    def map_range(old_range_level, cur_range_level, buf):\n",
    "        if cur_range_level != old_range_level and cur_range_level >= 1:\n",
    "            db = scn.linlin(cur_range_level, 1, 5, -40, 0, \"minmax\")\n",
    "            scn.Synth(\"playbuf\", {\"bufnum\": buf.bufnum, \"amp\": scn.dbamp(db)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = Percussive()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d1cff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebbd51a",
   "metadata": {},
   "source": [
    "#### Sonification: Multi-percussion sound with intensity direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectionalPercussive(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "    pan = ps.CheckboxParameter()\n",
    "    # hysteresis bounds relative to each intensity level\n",
    "    bounds = ps.FloatRangeSliderParameter(-1, +1)\n",
    "\n",
    "    playbuf_def = scn.SynthDef(\n",
    "        \"playbuf_bend\",\n",
    "        r\"\"\"{| out=0, bufnum=0, rateInitial=1, amp=1, pan=0, breakTime, rateFinal |\n",
    "            var sig, rate;\n",
    "\n",
    "            var rateAvg = (rateInitial + rateFinal) / 2;\n",
    "            var sampleRateAvg = rateAvg * BufSampleRate.kr(bufnum);\n",
    "            var breakFrame = breakTime * BufSampleRate.kr(bufnum);\n",
    "            // mono signal: frames = samples\n",
    "            var remainingFrames = BufSamples.kr(bufnum) - breakFrame;\n",
    "            // calculate remaining time with dynamic rate\n",
    "            var remainingTime = remainingFrames / sampleRateAvg;\n",
    "\n",
    "            rate = EnvGen.kr(\n",
    "                Env(\n",
    "                    [rateInitial, rateInitial, rateFinal],\n",
    "                    [breakTime, remainingTime]\n",
    "                )\n",
    "            );\n",
    "            sig = PlayBuf.ar(1, bufnum, rate*BufRateScale.kr(bufnum), doneAction:2);\n",
    "            Out.ar(0, Pan2.ar(sig, pan, amp));\n",
    "        }\"\"\"\n",
    "    )\n",
    "    \n",
    "    AUs = {\n",
    "        1: {\n",
    "            'label': \"AU01_r\",\n",
    "            'path': AU01_SAMPLE_PATH,\n",
    "            'break_time': 0.2,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        2: {\n",
    "            'label': \"AU02_r\",\n",
    "            'path': AU02_SAMPLE_PATH,\n",
    "            'break_time': 0.2,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        4: {\n",
    "            'label': \"AU04_r\",\n",
    "            'path': AU04_SAMPLE_PATH,\n",
    "            'break_time': 0.2,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        5: {\n",
    "            'label': \"AU05_r\",\n",
    "            'path': AU05_SAMPLE_PATH,\n",
    "            'break_time': 0.05,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        6: {\n",
    "            'label': \"AU06_r\",\n",
    "            'path': AU06_SAMPLE_PATH,\n",
    "            'break_time': 0.03,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        7: {\n",
    "            'label': \"AU07_r\",\n",
    "            'path': AU07_SAMPLE_PATH,\n",
    "            'break_time': 0.1,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        9: {\n",
    "            'label': \"AU09_r\",\n",
    "            'path': AU09_SAMPLE_PATH,\n",
    "            'break_time': 0.2,\n",
    "            'rate_up': 1.5,\n",
    "            'rate_down': 0.7\n",
    "        },\n",
    "        10: {\n",
    "            'label': \"AU10_r\",\n",
    "            'path': AU10_SAMPLE_PATH,\n",
    "            'break_time': 0.15,\n",
    "            'rate_up': 1.2,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        12: {\n",
    "            'label': \"AU12_r\",\n",
    "            'path': AU12_SAMPLE_PATH,\n",
    "            'break_time': 0.1,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        14: {\n",
    "            'label': \"AU14_r\",\n",
    "            'path': AU14_SAMPLE_PATH,\n",
    "            'break_time': 0.1,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        15: {\n",
    "            'label': \"AU15_r\",\n",
    "            'path': AU15_SAMPLE_PATH,\n",
    "            'break_time': 0.05,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        17: {\n",
    "            'label': \"AU17_r\",\n",
    "            'path': AU17_SAMPLE_PATH,\n",
    "            'break_time': 0.05,\n",
    "            'rate_up': 1.5,\n",
    "            'rate_down': 0.8\n",
    "        },\n",
    "        20: {\n",
    "            'label': \"AU20_r\",\n",
    "            'path': AU20_SAMPLE_PATH,\n",
    "            'break_time': 0.1,\n",
    "            'rate_up': 1.1,\n",
    "            'rate_down': 0.9\n",
    "        },\n",
    "        23: {\n",
    "            'label': \"AU23_r\",\n",
    "            'path': AU23_SAMPLE_PATH,\n",
    "            'break_time': 0.15,\n",
    "            'rate_up': 1.25,\n",
    "            'rate_down': 0.85\n",
    "        },\n",
    "        25: {\n",
    "            'label': \"AU25_r\",\n",
    "            'path': AU25_SAMPLE_PATH,\n",
    "            'break_time': 0.005,\n",
    "            'rate_up': 2,\n",
    "            'rate_down': 0.5\n",
    "        },\n",
    "        26: {\n",
    "            'label': \"AU26_r\",\n",
    "            'path': AU26_SAMPLE_PATH,\n",
    "            'break_time': 0.05,\n",
    "            'rate_up': 2,\n",
    "            'rate_down': 0.5\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, pan=False):\n",
    "        super().__init__()\n",
    "        self.amp = 0.3\n",
    "        self.pan = False\n",
    "        self.bounds = [-0.3, +0.3]\n",
    "\n",
    "        self.old_levels = {}\n",
    "\n",
    "    @bundle\n",
    "    def init(self):\n",
    "        self.playbuf_def.add()\n",
    "        \n",
    "        self.buffers = {}\n",
    "        \n",
    "        # allocate buffers\n",
    "        for i, info in self.AUs.items():\n",
    "            self.buffers[i] = scn.Buffer().read(info['path'])\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        # initialize old range levels\n",
    "        for i in self.AUs.keys():\n",
    "            self.old_levels[i] = 0\n",
    "    \n",
    "    @bundle\n",
    "    def stop(self):\n",
    "        # synths die out alone\n",
    "        pass\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        for i, info in self.AUs.items():\n",
    "            intensity = row[info['label']]\n",
    "            cur_range_level = self.map_intensity(intensity, self.old_levels[i])\n",
    "            \n",
    "            if cur_range_level != self.old_levels[i] and cur_range_level >= 1:\n",
    "                db = scn.linlin(cur_range_level, 1, 5, -40, 0, \"minmax\")\n",
    "                amp = scn.dbamp(db)\n",
    "            \n",
    "                if cur_range_level > self.old_levels[i]:\n",
    "                    scn.Synth(\n",
    "                        \"playbuf_bend\",\n",
    "                        {\n",
    "                            \"bufnum\": self.buffers[i].bufnum,\n",
    "                            \"amp\": self.amp * amp,\n",
    "                            \"pan\": 1 if self.pan else 0,\n",
    "                            \"breakTime\": info['break_time'],\n",
    "                            \"rateFinal\": info['rate_up']\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    scn.Synth(\n",
    "                        \"playbuf_bend\",\n",
    "                        {\n",
    "                            \"bufnum\": self.buffers[i].bufnum,\n",
    "                            \"amp\": self.amp * amp,\n",
    "                            \"pan\": -1 if self.pan else 0,\n",
    "                            \"breakTime\": info['break_time'],\n",
    "                            \"rateFinal\": info['rate_down']\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "            # update old_range_level\n",
    "            self.old_levels[i] = cur_range_level\n",
    "\n",
    "    def map_intensity(self, intensity, old_level):\n",
    "        cur_level = int(intensity)\n",
    "        \n",
    "        if cur_level == old_level:\n",
    "            return cur_level        \n",
    "        elif cur_level > old_level:\n",
    "            return cur_level if intensity > cur_level + self.bounds[1] else old_level\n",
    "        elif cur_level < old_level:\n",
    "            return cur_level if intensity < old_level + self.bounds[0] else old_level\n",
    "            \n",
    "    def free(self):\n",
    "        # deallocate buffers\n",
    "        for info in self.AU.values():\n",
    "            info['buf'].free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = DirectionalPercussive()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25897bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "son.free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca03973",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fb4fe",
   "metadata": {},
   "source": [
    "### Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay(['pose_Rx', 'pose_Ry', 'pose_Rz'], queue_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babbc6fa",
   "metadata": {},
   "source": [
    "#### Sonification: Head rotations with constant amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.amp = 0.1\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.synth = scn.Synth(\"s2\", {\"amp\": 0, \"lg\": 0.015})\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        pitch = scn.linlin(row['pose_Rx'], -pi/2, +pi/2, 69+12, 69-12)\n",
    "        pan =   scn.linlin(row['pose_Ry'], -pi/2, +pi/2, +1, -1)\n",
    "        num =   scn.linlin(row['pose_Rz'], -pi/4, +pi/4, 1, 7)\n",
    "        \n",
    "        self.synth.set(\n",
    "            \"amp\", self.amp,\n",
    "            \"freq\", scn.midicps(pitch),\n",
    "            \"pan\", pan,\n",
    "            \"num\", num\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = Head()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "feature_display.show(5)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad780c28",
   "metadata": {},
   "source": [
    "#### Sonification: Head rotations with silent neutral position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db24c7",
   "metadata": {},
   "source": [
    "The amplitude is mapped linearly based on the biggest rotation.\n",
    "* a linear mapping makes quiet sounds more distinguishable\n",
    "* every axe has a silence thrashold, so that a head in a pretty neutral position does not generate any sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a143c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SilentHead(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    # max expected values for each rotation\n",
    "    rx_bound = pi/2\n",
    "    ry_bound = pi/2\n",
    "    rz_bound = pi/4\n",
    "    \n",
    "    # in radians\n",
    "    rx_silence_thrashold = rx_bound / 10\n",
    "    ry_silence_thrashold = ry_bound / 10\n",
    "    rz_silence_thrashold = rz_bound / 10\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.amp = 0.3\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.synth = scn.Synth(\"s2\", {\"amp\": 0, \"lg\": 0.015})\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        rx, ry, rz = row[['pose_Rx', 'pose_Ry', 'pose_Rz']]\n",
    "        \n",
    "        # linear mapping\n",
    "        amp = max(\n",
    "            # clips values under silence thrashold\n",
    "            scn.linlin(abs(rx), self.rx_silence_thrashold, +self.rx_bound, 0, 1, \"minmax\"),\n",
    "            scn.linlin(abs(ry), self.ry_silence_thrashold, +self.ry_bound, 0, 1, \"minmax\"),\n",
    "            scn.linlin(abs(rz), self.rx_silence_thrashold, +self.rz_bound, 0, 1, \"minmax\")\n",
    "        )\n",
    "        \n",
    "        pitch = scn.linlin(rx, -self.rx_bound, +self.rx_bound, 69+12, 69-12)\n",
    "        pan =   scn.linlin(ry, -self.ry_bound, +self.ry_bound, +1, -1)\n",
    "        num =   scn.linlin(rz, -self.rz_bound, +self.rz_bound, 1, 7)\n",
    "        \n",
    "        self.synth.set(\n",
    "            \"amp\", self.amp * amp,\n",
    "            \"freq\", scn.midicps(pitch),\n",
    "            \"pan\", pan,\n",
    "            \"num\", num\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1819c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = SilentHead()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "feature_display.show(5)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec9006",
   "metadata": {},
   "source": [
    "#### Sonification: Noisy head rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyHead(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1)\n",
    "    base_tone = ps.MidiSliderParameter()\n",
    "    log_mapping = ps.CheckboxParameter()\n",
    "    \n",
    "    # max expected values for each rotation\n",
    "    rx_bound = ps.FloatSliderParameter(pi/2 / 10, pi/2)\n",
    "    ry_bound = ps.FloatSliderParameter(pi/2 / 10, pi/2)\n",
    "    rz_bound = ps.FloatSliderParameter(pi/2 / 10, pi/2)\n",
    "    \n",
    "    synth_def = scn.SynthDef(\n",
    "        \"bpf_noise\",\n",
    "        r\"\"\"{ | amp=1, pan=0, lg=0.5, freq=440, rq=0.2 |\n",
    "            var sig;\n",
    "            sig = PinkNoise.ar(amp);\n",
    "            sig = BPF.ar(\n",
    "                sig,\n",
    "                freq.lag(lg),\n",
    "                rq.lag(lg),\n",
    "                // when a bandpass filter narrows, the amplitude decreases: this will balance it\n",
    "                1/rq.sqrt.lag(lg)\n",
    "            );\n",
    "            Out.ar(0, Pan2.ar(sig, pan));\n",
    "        }\"\"\"\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.amp = 0.3\n",
    "        self.base_tone = 69\n",
    "        self.log_mapping = False\n",
    "        \n",
    "        self.rx_bound = pi/2\n",
    "        self.ry_bound = pi/2\n",
    "        self.rz_bound = pi/4\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        self.synth_def.add()\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.synth = scn.Synth(\"bpf_noise\", {\"amp\": 0, \"lg\": 0.015})\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        rx, ry, rz = row[['pose_Rx', 'pose_Ry', 'pose_Rz']]\n",
    "        \n",
    "        # use log() - 1 to map\n",
    "        if self.log_mapping:\n",
    "            rx_log = log2(scn.linlin(abs(rx), 0, self.rx_bound, 1, 2, 'minmax'))\n",
    "            rx_midi = scn.linlin(rx_log, 0, 1, 0, 12, 'minmax')\n",
    "            sign = 1 if rx >= 0 else -1\n",
    "            pitch = self.base_tone + sign * rx_midi\n",
    "            \n",
    "            ry_exp = scn.linlin(abs(ry), 0, self.ry_bound, 1, 2, 'minmax')\n",
    "            sign = 1 if ry >= 0 else -1\n",
    "            pan = sign * log2(ry_exp)\n",
    "                        \n",
    "            q =   scn.linlin(rz, -self.rz_bound, +self.rz_bound, 1, 100, 'minmax')\n",
    "            \n",
    "        else:\n",
    "            pitch = scn.linlin(rx, -self.rx_bound, +self.rx_bound, 69+12, 69-12, \"minmax\")\n",
    "            pan =   scn.linlin(ry, -self.ry_bound, +self.ry_bound, +1, -1, \"minmax\")\n",
    "            # linexp mapping to quality\n",
    "            q =   exp(scn.linlin(rz, -self.rz_bound, +self.rz_bound, log2(1), log2(100), 'minmax'))\n",
    "        \n",
    "        self.synth.set(\n",
    "            \"amp\", self.amp,\n",
    "            \"freq\", scn.midicps(pitch),\n",
    "            \"pan\", pan,\n",
    "            \"rq\", 1/q\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = NoisyHead()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963f42c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "feature_display.show(5)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd52e1",
   "metadata": {},
   "source": [
    "### Gaze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa7f98",
   "metadata": {},
   "source": [
    "**gaze_N_x, gaze_N_y, gaze_N_z**: Eye gaze **direction vector** in world coordinates for eye left and right eye (normalized)\n",
    "- N = 0: leftmost eye in the image\n",
    "- N = 1: rightmost eye in the image\n",
    "\n",
    "**gaze_angle_x, gaze_angle_y**: Eye gaze direction in radians in world coordinates averaged for both eyes and converted into more **easy to use format** than gaze vectors.\n",
    "- If a person is looking left-right this will results in the change of gaze_angle_x (from positive to negative)\n",
    "- if a person is looking up-down this will result in change of gaze_angle_y (from negative to positive)\n",
    "- if a person is looking straight ahead both of the angles will be close to 0 (within measurement error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay(['gaze_angle_x', 'gaze_angle_y'], queue_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057d64f",
   "metadata": {},
   "source": [
    "#### Sonification: Gaze with constant amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a000a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaze(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.amp = 0.1\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.synth = scn.Synth(\"s2\", {\"amp\": 0, \"lg\": 0.015})\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        pitch = scn.linlin(row['gaze_angle_y'], -pi/2, +pi/2, 69+12, 69-12)\n",
    "        pan =   scn.linlin(row['gaze_angle_x'], -pi/2, +pi/2, +1, -1)\n",
    "        \n",
    "        self.synth.set(\n",
    "            \"amp\", self.amp,\n",
    "            \"freq\", scn.midicps(pitch),\n",
    "            \"pan\", pan\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be23b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = Gaze()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "feature_display.show(5)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f6c3f",
   "metadata": {},
   "source": [
    "#### Sonification: Gaze with silent neutral position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SilentGaze(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "    \n",
    "    gx_silence_thrashold = ps.FloatSliderParameter(0, pi/2, 0.01)\n",
    "    gy_silence_thrashold = ps.FloatSliderParameter(0, pi/2, 0.01)\n",
    "    \n",
    "    freq = ps.FreqSliderParameter()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.amp = 0.1\n",
    "        self.gx_silence_thrashold = pi/2 / 10\n",
    "        self.gy_silence_thrashold = pi/2 / 10\n",
    "        \n",
    "        self.freq = 50\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        scn.SynthDef.load(\"/home/michele/Desktop/Thesis/tools/sc3nb/src/sc3nb/resources/synthdefs/s2.scsyndef\")\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.synth = scn.Synth(\"s2\", {\"amp\": 0, \"lg\": 0.015})\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        \n",
    "        gx, gy = row[['gaze_angle_x', 'gaze_angle_y']]\n",
    "        \n",
    "        # linear mapping\n",
    "        amp = max(\n",
    "            # clips values under silence thrashold\n",
    "            scn.linlin(abs(gx), self.gx_silence_thrashold, pi/2, 0, 1, \"minmax\"),\n",
    "            scn.linlin(abs(gy), self.gy_silence_thrashold, pi/2, 0, 1, \"minmax\")\n",
    "        )\n",
    "        \n",
    "        pan =   scn.linlin(gx, -pi/2, +pi/2, -1, +1)\n",
    "        pitch = scn.linlin(gy, -pi/2, +pi/2, 69+12, 69-12)\n",
    "        \n",
    "        self.synth.set(\n",
    "            \"amp\", self.amp * amp,\n",
    "            \"freq\", scn.midicps(pitch),\n",
    "            \"pan\", pan\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = SilentGaze()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "feature_display.show(5)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f647cd",
   "metadata": {},
   "source": [
    "### Smile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f2208",
   "metadata": {},
   "source": [
    "AUs regarding the smile recognised by OpenFace:\n",
    "* AU06 - Cheek raiser\n",
    "* AU12 - Lip Corner Puller\n",
    "* AU14 - Dimpler\n",
    "* AU15 - Lip Corner Depressor\n",
    "* AU17 - Chin Raiser\n",
    "\n",
    "Expected to go together:\n",
    "* AU06 - AU12\n",
    "* AU15 - AU17\n",
    "\n",
    "For now we will ignore AU14 for simplicity, and we will sonify it using the percussive approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ec2df",
   "metadata": {},
   "source": [
    "TODO: musical sonification of the smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.LiveFeatureDisplay(['AU06_r', 'AU12_r', 'AU15_r', 'AU17_r'], queue_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d717a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DustSmile(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1)\n",
    "    base_tone = ps.MidiSliderParameter()\n",
    "    \n",
    "    synth_def = scn.SynthDef(\n",
    "        \"discrete_rev\",\n",
    "        r\"\"\"{ | amp=1, freq=440, density=2, mix=0.5, room=0.5, damp=0.2, lg=0.1 |\n",
    "            var trig, sig, env;\n",
    "            sig = SinOsc.ar(freq);\n",
    "            // transform signal into short blips\n",
    "            trig = Dust.kr(density);\n",
    "            env = EnvGen.kr(Env.perc(0.001, 0.05), trig);\n",
    "            sig = sig * env;\n",
    "            sig = FreeVerb.ar(sig, mix.lag(lg), room.lag(lg), damp.lag(lg), amp.lag(lg));\n",
    "            Out.ar(0, sig!2);\n",
    "        }\"\"\"\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.amp = 0.3\n",
    "        self.base_tone = 69\n",
    "    \n",
    "    @bundle\n",
    "    def init(self):\n",
    "        self.synth_def.add()\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        self.synth = scn.Synth(\"discrete_rev\", {\"amp\": 0})\n",
    "    \n",
    "    @bundle\n",
    "    def _process(self, row):\n",
    "        # intensities\n",
    "        au06, au12, au15, au17 = row[['AU06_r', 'AU12_r', 'AU15_r', 'AU17_r']]\n",
    "\n",
    "        if au12 > 1 and au15 > 1:\n",
    "            # this should not happen usually\n",
    "            return\n",
    "        \n",
    "        if au12 > 1:\n",
    "            pitch = scn.linlin(au12, 1, 5, self.base_tone, self.base_tone+12, 'minmax')\n",
    "            mix = scn.linlin(au06, 1, 3, 0.2, 1, 'minmax')\n",
    "            density = scn.linlin(max(au12, au06), 1, 5, 5, 30, 'minmax')\n",
    "        elif au15 > 1:\n",
    "            pitch = scn.linlin(au15, 1, 5, self.base_tone, self.base_tone-12, 'minmax')\n",
    "            mix = scn.linlin(au17, 1, 3, 0.2, 1, 'minmax')\n",
    "            density = scn.linlin(max(au15, au17), 1, 5, 5, 30, 'minmax')\n",
    "        else:\n",
    "            pitch = 69\n",
    "            mix = 0\n",
    "            density = 0\n",
    "        \n",
    "        self.synth.set(\n",
    "            \"amp\", self.amp,\n",
    "            \"freq\", scn.midicps(pitch),\n",
    "            \"mix\", mix,\n",
    "            \"density\", density,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56898c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = DustSmile()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son, feature_display)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "feature_display.show(5)\n",
    "rtdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8aca1",
   "metadata": {},
   "source": [
    "### All togheter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098996ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = ps.GroupSonification([DirectionalPercussive(), DropBlink(), NoisyHead(), SilentGaze()])\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65d7f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rtdp = ps.RTDataPlayer(data_generator, son)\\\n",
    "        .add_listen_hook(feature_extraction_online)\\\n",
    "        .add_close_hook(kill_feature_extraction_online)\n",
    "rtdp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face]",
   "language": "python",
   "name": "conda-env-face-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
