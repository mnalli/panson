{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a9df36-fbbf-485e-950e-a1de63867203",
   "metadata": {},
   "source": [
    "# Non-realtime Sonification\n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366fce4-3c7f-4299-938b-766def67ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sc3nb as scn\n",
    "\n",
    "# start scsynth\n",
    "sc = scn.startup()\n",
    "\n",
    "# connect supercollider server to system output\n",
    "!jack_connect \"SuperCollider:out_1\" \"system:playback_1\"\n",
    "!jack_connect \"SuperCollider:out_2\" \"system:playback_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86e250-c168-4934-839e-f0ad6e89e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4ce92-c559-4457-882d-841fef0ded61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test supercollider output\n",
    "sc.server.blip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ba057-3b7c-49b4-93c2-eaaafd6f6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.server.latency = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fda7e-f5ea-4432-81d1-890ea0d595a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# name given to the container\n",
    "CONTAINER_NAME = 'openface'\n",
    "\n",
    "# base directory of the container\n",
    "CONTAINER_BASE_DIR = '/home/openface-build'\n",
    "# directory with executalbles in the container\n",
    "CONTAINER_BIN_DIR = os.path.join(CONTAINER_BASE_DIR, 'build/bin')\n",
    "\n",
    "CONTAINER_FILE_DIR = os.path.join(CONTAINER_BASE_DIR, 'files')\n",
    "CONTAINER_OUT_DIR  = os.path.join(CONTAINER_FILE_DIR, 'processed')\n",
    "\n",
    "CONTAINER_EXECUTABLE = os.path.join(CONTAINER_BIN_DIR, 'FeatureExtraction')\n",
    "\n",
    "# mounted local directories\n",
    "FILE_DIR = 'mount'\n",
    "\n",
    "\n",
    "def feature_extraction_offline(video_name):\n",
    "    \"\"\"Perform feature extraction on video file.\"\"\"\n",
    "    \n",
    "    video_path = os.path.join(FILE_DIR, video_name)\n",
    "    \n",
    "    # the file must be in FILE_DIR\n",
    "    if not os.path.isfile(video_path):\n",
    "        raise FileNotFoundError(video_path)\n",
    "    \n",
    "    container_video_path = os.path.join(CONTAINER_FILE_DIR, video_name)\n",
    "    \n",
    "    command = [\n",
    "        'docker', 'exec', CONTAINER_NAME, CONTAINER_EXECUTABLE,\n",
    "        '-f', container_video_path,\n",
    "        '-out_dir', CONTAINER_OUT_DIR,\n",
    "        # features extracted\n",
    "        '-pose', '-gaze', '-aus',\n",
    "        # output tracked video\n",
    "        '-tracked'\n",
    "    ]\n",
    "    \n",
    "    # capture and combine stdout and stderr into one stream and set as text stream\n",
    "    proc = subprocess.Popen(command,stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "        \n",
    "    # poll process and show its output\n",
    "    while True:\n",
    "        output = proc.stdout.readline()\n",
    "        \n",
    "        if output:\n",
    "            print(output.strip())\n",
    "            \n",
    "        if proc.poll() is not None:\n",
    "            break\n",
    "    \n",
    "    return proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125cff6-e2f9-4111-8fd1-d76bd91b367e",
   "metadata": {},
   "source": [
    "When executing **offline feature extraction**, sometimes OpenFace will drop some frames without processing them, causing the output data (and tracked video output) to be inaccurate. This may be related to OpenCV not being able to work with some of the codecs, but in general this is an open issue of OpenFace.\n",
    "\n",
    "One workaround is to:\n",
    "1. Split video frames into separate images\n",
    "    * `ffmpeg -i video.avi video_dir/frame%04d.jpg`\n",
    "2. Instruct OpenFace to process the frame directory with the `-fdir` option\n",
    "    * The csv output of openface will not contain timestamp information, so we would have to recreate them from frame files names\n",
    "\n",
    "Here we will not be using this workaround."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f664296-0fe7-49ab-a74e-a1c175a387df",
   "metadata": {},
   "source": [
    "The following functions are used to perform operations on video files using `ffmpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09543a-2d0f-4e51-b62f-ed2e36f58fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert video file from one format to the other\n",
    "!ffmpeg -y -i in_file -c:v libx264 -crf 22 -pix_fmt yuv420p -c:a libvo_aacenc -b:a 128k out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73fa93-9b5e-4275-b7dd-56e904efb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge audio and video files\n",
    "!ffmpeg -y -i video_file -i audio_file -map 0:v -map 1:a -c:v copy out_file\n",
    "# ffmpeg -i files/phone-processed.mp4 -i score.wav  -c:v copy phone-processed-son.mp4 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eb15fa-b570-4c94-a8ec-74adbb409571",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "In this way it is possible to load the feature extraction data produced by OpenFace executables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a54b29-51ea-4c15-ab41-f9b645b37d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"mount/processed/phone.csv\", sep=r',\\s*', engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e9cea-67c4-4040-9654-5300277b4f06",
   "metadata": {},
   "source": [
    "## Sonification: AU04 Test\n",
    "\n",
    "This sonification is similar to the previous sonifications, but with the addition of a parameter for amplitude regulation.\n",
    "\n",
    "This is a very simple sonification of AU04 (Brow Lowerer). The intensity of AU04 is used here to modulate both the amplitude and the frequency of a continuous synth. As continuous synth, the default synth of sc3nb s2 is used (we will have to instruct the server to load it).\n",
    "\n",
    "* The intensity range \\[0,1\\] is mapped into the amplitude range \\[0,0.3\\], where 0.3 will be the maximum amplitude of the sound. The sonification has a parameter amp that can be used to scale this range.\n",
    "* The intensity range \\[0,5\\] is mapped into the midi range \\[69,81\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b89834-c8e2-4d37-9126-2a7cd4172060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panson as ps\n",
    "from panson import bundle\n",
    "\n",
    "class AU04ContinuousSonification(ps.Sonification):\n",
    "    \n",
    "    # parameters of the sonification\n",
    "    amp = ps.FloatSliderParameter(0, 1, 0.01)\n",
    "        \n",
    "    def init_parameters(self):\n",
    "        self.amp = 1\n",
    "    \n",
    "    @bundle\n",
    "    def init_server(self):\n",
    "        self.s.load_synthdefs()\n",
    "\n",
    "    @bundle\n",
    "    def start(self):\n",
    "        # lag time is decided based on the frame rate\n",
    "        self.synth = scn.Synth(\"s2\", {\"amp\": 0, \"lg\": 0.03})\n",
    "\n",
    "    @bundle\n",
    "    def _process(self, row):  \n",
    "        self.synth.set(\n",
    "            # only \"max\" should be enough (to clip the top part to 0.3)\n",
    "            \"amp\", self.amp * scn.linlin(row[\"AU04_r\"], 0, 1, 0, 0.3, \"minmax\"),\n",
    "            # map the intensity of the AU in one octave range\n",
    "            \"freq\", scn.midicps(scn.linlin(row[\"AU04_r\"], 0, 5, 69, 81))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35872117-891c-47c2-bc49-88e49998255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "son = AU04ContinuousSonification()\n",
    "son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972dcd62-73eb-4eb1-b5a6-a134f6a58063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('widget')\n",
    "\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae28db-9a29-4a8f-9734-13bcf7627cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = ps.VideoPlayer('mount/processed/phone.avi', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e88794-900e-494d-80a7-b8726d59f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display = ps.RTFeatureDisplay(['AU04_r', 'AU12_r'], queue_size=50)\n",
    "dp = ps.DataPlayer(son, feature_display=feature_display, video_player=vp).load(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db1c07-8c43-46a8-820f-ba22da84004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_display.show(fps=30)\n",
    "display(son)\n",
    "display(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094fafd5-b377-42af-ac02-ff43127f747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
