{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Sonification Mockup Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "panson = sonify everything\n",
    "* pan --> from the greek παν: everything\n",
    "* son --> sonify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* serialize/deserialize sonifications (with parameters)\n",
    "    * serialize groups of sonifications\n",
    "    * pickle\n",
    "        * https://stackoverflow.com/questions/4529815/saving-an-object-data-persistence/4529901\n",
    "        * pickle should always be preferred to marshall (https://docs.python.org/3/library/pickle.html)\n",
    "* register callbacks\n",
    "    * at initialization time\n",
    "    * at each playback\n",
    "    * at export time\n",
    "* a Sonification can contain other Sonifications\n",
    "    * use a class CompositeSonification?\n",
    "    * maybe it is not a urgent feature\n",
    "* support playback of audio/video data\n",
    "    * use external process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How much do DataPlayer and RTDataPlayer have in common?\n",
    "    * Define base class?\n",
    "    * record\n",
    "* How to synchronize media if a number of streams are involved?\n",
    "    * types of stream\n",
    "        * video stream (without audio)\n",
    "        * audio stream\n",
    "            * need for **pya**?\n",
    "        * sensor data stream\n",
    "    * we have to be able to record all kinds of stream\n",
    "    * streams can have different sampling rates\n",
    "        * the logged dataframe must have coherent timestamps\n",
    "* Once data are logged in a data frame, a frequent use case is to replay the data\n",
    "    * show\n",
    "        * the video\n",
    "        * the sonification of the data\n",
    "        * the data (visually, e.g. as time series plot)\n",
    "            * still have to think about this, but we should be able to display it over the player navigation panel\n",
    "    * everything must be syncronized\n",
    "    * we must be able to change the parameters of the sonification as we go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonification, DataPlayer, RTDataPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import framework\n",
    "import panson as ps # maybe it is easy to confuse with pd\n",
    "import pandas as pd\n",
    "\n",
    "import sc3nb as scn\n",
    "scn.startup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sonification objects by inheriting from the Sonification class (abstract base class). This object will be used in **both realtime and non-realtime** contexts.\n",
    "* we could insert in the framework a little library of working sonifications (based on some sample data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sonification logic should be written just once and have both NRT and normal sonification available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySonification(ps.Sonification):\n",
    "    \n",
    "    def initialize():\n",
    "        pass\n",
    "    \n",
    "    # sonify the current row and return it in a bundle?\n",
    "    def sonify(row):\n",
    "        pass\n",
    "    \n",
    "    def end():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "son = MySonification(parameters)\n",
    "son"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluated in the notebook, son should return a widget to control the parameters of the sonification. If we change the parameters, the playing sonification should update.\n",
    "\n",
    "The parameters of the sonification can be changed:\n",
    "* programmatically, e.g. son.amp = 0.3\n",
    "* through the widget interface\n",
    "    * it's probably better to use input fields rather than sliders (or maybe use both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data player takes as an input the **sonification** to be used and the **dataframe** to be sonified.\n",
    "* we may also allow the user to set or modify them after the creation of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = ps.DataPlayer(son, df)\n",
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluated in the notebook, dp should return a widget to control the playback of the data. The interface would be ideally similar to widgets.Play, but with more options.\n",
    "* we cannot use widgets.Play directly because its logic is not appropriate for our purposes\n",
    "\n",
    "The data player should be able to specify a **constant playback rate** or to use **timestamp information** in the data.\n",
    "* `DataPlayer(son, df, playback_rate=30)`\n",
    "    * 30 data rows per second\n",
    "    * there can't be any default for playback_rate that is meaningful with every data\n",
    "        * when the argument is specified the DataPlayer will not consider any timestamp information\n",
    "        * when the argument is not specified the DataPlayer will look for timestamp information in the data\n",
    "            * `df['timestamp']` by default\n",
    "            * `DataPlayer(son, df, timestamp_key='time')`\n",
    "                * this way we can override the default timestamp lookup key\n",
    "                \n",
    "\n",
    "The DataPlayer object could also register **multiple sonification objects**, so that we could have more modular design, e.g. use separate sonifications for the smile and for the eyebrows and play them together.\n",
    "* better to use CompositeSonification\n",
    "\n",
    "DataPlayer would load all the csv in memory. This is not necessairly the best solution in case of a huge csv file\n",
    "* we can use pandas chunking support\n",
    "* https://stackoverflow.com/questions/29334463/how-can-i-partially-read-a-huge-csv-file/44958125\n",
    "\n",
    "We should be able to **create a DataPlayer also from a path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_video(df_row):\n",
    "    # update videoframe\n",
    "    pass\n",
    "\n",
    "dp.add_callback('update_video', update_video)\n",
    "# dp.del_callback('update_video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it useful we have to allow the registration of callbacks also during initialization (and in other moments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real-time sonification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control the data playback by using the **widget interface** or by using the **following methods**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.play()\n",
    "# dp.play(rate=2)\n",
    "# dp.play(rate=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.seek(frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.seektime(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus other possible navigation functions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method would record what is currently being played.\n",
    "* NOTE: maybe its not a good idea to call the class DataPlayer if it allows recording\n",
    "* maybe we can provde a context manager to record\n",
    "* change name in **capture**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.record_start('recording.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.record_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the relationship between record_stop and the navigation methods? Should they be independent or not?\n",
    "* pause\n",
    "* stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record for 10 second (the recording stops automatically)\n",
    "dp.record_start('recording.wav', duration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non real-time sonification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can render the NRT sonification using the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.export('sonification.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe export is not the best name:\n",
    "* render\n",
    "* nrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamz (https://streamz.readthedocs.io/en/latest/core.html) seems to add only microsecond overhead to normal Python operations.\n",
    "* there should not be any performance issues using it\n",
    "* maybe we don't really need the library and we can write easier code without it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could write a mainloop where read live data and input it into the RTDataPlayer, but this would block the main thread. This is a problem because we would want to interact programmatically with the RTDataPlayer later on.\n",
    "\n",
    "It is better to encapsulate this in a method and run it in a separate thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acquisition of live feature is too dependent on the context to code it all in advance. The mainloop code should be specified by the user. We could pass a function at object creation time, but it's clearer if we define RTDataPlayer as an abstract base class and we instantiate custom subclasses of it. E.g. in NamedPipeDataPlayer the data player would read data from a specified named pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedPipeDataPlayer(ps.RTDataPlayer):\n",
    "    \n",
    "    def data_loop(self, fifo_path):\n",
    "        # open a named pipe and parse the data in the expected format        \n",
    "        with open(fifo_path, 'r') as fifo:\n",
    "            # the reader attempts to execute fifo.readline() (which is blocking if there are no lines)\n",
    "            reader = csv.reader(fifo)\n",
    "\n",
    "            # the loop ends when the pipe is closed from the writing side\n",
    "            for row in reader:\n",
    "                # input data the read row in the streamz Stream object\n",
    "                self.source.emit(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may be reading from different sources with different sampling rates, so we should have different threads, one listening on every source.\n",
    "* the GIL should not be a problem, as the threads should be IO-bound (the thread should block when waiting for the data)\n",
    "* we can setup a mechanism for registering sources of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp = NamedPipeDataPlayer(son)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the flow of data\n",
    "rtdp.listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record live sounds as with the DataPlayer\n",
    "rtdp.record_start('recording.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log real-time data with the following functions.\n",
    "* provide also a context manager?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp.log_start('logged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a DataPlayer object of the logged data\n",
    "rtdp.log_stop(return_dp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherwise we can create a DataPlayer this way\n",
    "dp = DataPlayer(son, 'logged_data.csv')\n",
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "* It is not clear which are the responsabilities of the objects, e.g. DataPlayers allow recording\n",
    "    * change its name?\n",
    "* How to write sonification logic only once?\n",
    "    * row sonification function could return a bundle, so that the routing part (to the server or to a score file through NRT) would be handled by the framework\n",
    "* RTDataPlayer can be hard to understand, even if the method should be flexible\n",
    "* Jupyter notebook widgets are able to support all these operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVC based\n",
    "* Model: SonificationModel (OnlineDataModel, OfflineDataModel)\n",
    "* View: OnlineView, OfflineView\n",
    "* Controller: OfflineController, OnlineController\n",
    "\n",
    "This seems to be a standard and easily understandable design, but I don't know if it is a good idea to apply it in a jupyter notebook environment:\n",
    "* the programmatic interaction could become more complex\n",
    "    * should we also force the programmatic interaction through the controller?\n",
    "    * the MVC is usually used in different contexts, where the only interaction happens through the GUI\n",
    "* in a jupyter notebook we could have various sonifications rendered through widgets and plug only one at a time in the DataPlayer\n",
    "    * usually the view is conceived as a monolithic entity, which means that we should render the sonification widget together with the playback widget. This would make the everything less pluginable and flexible, e.g. we have to re-render all the view if we change the sonification\n",
    "        * is it actually a problem?\n",
    "* A MVC architecture applied in a context where it does not fit well (i.e. where the user of the framework has other expectations) could generate a lot of confusion.\n",
    "    * maybe it would be better to adopt a completely different structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonification, DataProcessor, RTDataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution is kind of similar to Thomas' one.\n",
    "\n",
    "* Sonification as in the first example\n",
    "* DataProcessor - coordinates the following elements:\n",
    "    * Sonification\n",
    "    * OfflineData (does not necessairly have to be an object)\n",
    "    * DataPlayer\n",
    "* RTDataProcessor - coordinates the following elements:\n",
    "    * Sonification\n",
    "    * OnlineData (does not necessairly have to be an object)\n",
    "        * we can leverage streamz and use the emit method on a source (attribute)\n",
    "\n",
    "In the RTDataProcessor we don't need any RTDataPlayer, because there is no navigation and playback to perform. The main tasks of the RTDataProcessor are:\n",
    "* call the sonification on the current element obtained from the stream\n",
    "* log (save) the stream of data\n",
    "* does it makes sense to record the sounds produced by the sonification directly? Surely there must be a way to synchronize it with the logged data... the mechanism should be analogous to the one of DataProcessor.\n",
    "\n",
    "RTDataProcessor can also be used as a builder for DataProcessor (after recording).\n",
    "\n",
    "How can we handle streams of video or audio data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The framework should also contain some objects to simplify the building of the widget interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea seems to be overly complex. Here we are trying to separate the playback logic from the processing logic. The problem with this is that the user would naturally interact in a jupyter notebook context with the DataPlayer interface, implemented using ipywidgets; being forced by this method of interaction, it would feel unnatural to put the DataProcessor object in the middle. In any case, this separation wouldn't make clear either what the responsabilities of the objects are given that the sonification logic is already found in the Sonification class and the playback one in the DataPlayer; the DataProcessor would be left with the responsabilities of handling data and callbacks. Callbacks are more naturally handled by the DataPlayer, while handling data is not a complex matter given that we are working with files and we are helped by pandas and streamz.\n",
    "\n",
    "The most reasonable solution seems to be the easier one: the first. Here we interpret DataPlayer as in guitar player: an element that uses data (or a feature extraction) as its score and plays a sonification (instrument) over it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thomas' idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isfw as sf # import the \"interactive sonification framework\" package as sf \n",
    "import sc3nb as scn\n",
    "scn.startup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts = sf.RTStream() # create a rt stream for sensor data. This needs to be worked out... \n",
    "\n",
    "dp = sf.DataProcessor(source=rts) # create a data processor with data source connected to a rtstream \n",
    "\n",
    "dp.son = sf.PercussiveSon() # this needs to be worked out...., perhaps allow to pass an array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging\n",
    "dp.logfile = \"\" # default None, but if set, logging goes into file, \n",
    "                # if object is a DataFrame, log lines are appended\n",
    "dp.logging = True # default is False, True immediately could immediately start logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the processor\n",
    "dp.run() # this would automatically call self.son.initialize()\n",
    "         # and then for every incoming sensor data vector self.son.update(dp, dp.current_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can enjoy the sonification and perhaps tweak it a bit like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.level += 6 # add 6 dB global volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.mute() # to have silence for discussing with a colleague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.unmute() # to continue listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.running   # should return True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.source = None # disconnect the source, e.g. because we want to continue with recorded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.source = DataPlayer()\n",
    "pl = sf.DataPlayer(dp.data.copy()) # switch to just logged data from previous rt interaction\n",
    "dp.source = pl\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "would give the repr which states something like:<br>\n",
    "```150 frames, avg fps 21.5, dim=18``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.loop(from=80, to=-1) # configure player to loop segment from frame 80 to end\n",
    "pl.cue(frame=80)\n",
    "pl.start() # now we enjoy the sonification in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would like to attend to this in more detail and slow down by a factor of 2\n",
    "pl.rate = 0.5 # the player stretches times between rows by a 1/rate and so the sonification slows down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can work on some sonification parameters, let's for instance shorten the percussive sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.anyproperty_available_in_class *= 0.5 # in this case we assume we have a property for event duration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more convenient: create a widget to control a property\n",
    "wdg_1 = sf.parameter_widget(dp.son.anyproperty_available_in_class, (0.1, 1, 100))\n",
    "# in result of which we get a slider widget from 0.1 to 1 in 100 steps \n",
    "# so that we can control the parameter in realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that we need to see the video in parallel, so here we need to synchronize a video playback component with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for coding we stop temporarily the dp\n",
    "dp.pause() \n",
    "# actualy we could let it run but just stop new data from coming int\n",
    "dp.resume(); pl.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's interactively load the data\n",
    "dp.vidview = sf.VideoViewer(\"MyVideo.mp4\", mode=\"memory\") # loading the full video into memory\n",
    "dp.vidview\n",
    "\n",
    "# current doubt: perhaps vidview should not be part of dp but connected to pl? makes more sense...\n",
    "# such are issues to be thought about..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this could output the __repr__(), e.g.:<br>\n",
    "```Video: 18s at 30fps = 540 frames of res 800 x 640 x 3 (RGB)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.vidview.display() # a window pops up showing the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.parameter_widget(dp.vidview.currentframe, (0, dp.vidview.nrframes, 1))\n",
    "# a slider pops up which allows us to browse the video..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets play the video together with the sonification.\n",
    "# as it is already registered as vidview, it would automatically receive the frame number from the pd, so\n",
    "pl.resume() # will present"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
