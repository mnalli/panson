{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Sonification Mockup Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "panson = sonify everything\n",
    "* pan --> from the greek παν: everything\n",
    "* son --> sonify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* serialize/deserialize sonifications (with parameters)\n",
    "    * save to disk\n",
    "* register callbacks\n",
    "    * at initialization time\n",
    "    * at each playback\n",
    "    * at export time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonification, DataPlayer, RTDataPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import framework\n",
    "import panson as ps # maybe it is easy to confuse with pd\n",
    "import pandas as pd\n",
    "\n",
    "import sc3nb as scn\n",
    "scn.startup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sonification objects by inheriting from the Sonification class (abstract base class). This object will be used in **both realtime and non-realtime** contexts.\n",
    "* we could insert in the framework a little library of working sonifications (based on some sample data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sonification logic should be written just once and have both NRT and normal sonification available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySonification(ps.Sonification):\n",
    "    \n",
    "    def initialize():\n",
    "        pass\n",
    "    \n",
    "    # sonify the current row and return it in a bundle?\n",
    "    def sonify(row):\n",
    "        pass\n",
    "    \n",
    "    def end():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "son = MySonification(parameters)\n",
    "son"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluated in the notebook, son should return a widget to control the parameters of the sonification. If we change the parameters, the playing sonification should update.\n",
    "\n",
    "The parameters of the sonification can be changed:\n",
    "* programmatically, e.g. son.amp = 0.3\n",
    "* through the widget interface\n",
    "    * it's probably better to use input fields rather than sliders (or maybe use both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data player takes as an input the **sonification** to be used and the **dataframe** to be sonified.\n",
    "* we may also allow the user to set or modify them after the creation of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = ps.DataPlayer(son, df)\n",
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluated in the notebook, dp should return a widget to control the playback of the data. The interface would be ideally similar to widgets.Play, but with more options.\n",
    "* we cannot use widgets.Play directly because its logic is not appropriate for our purposes\n",
    "\n",
    "The data player should be able to specify a **constant playback rate** or to use **timestamp information** in the data.\n",
    "* `DataPlayer(son, df, playback_rate=30)`\n",
    "    * 30 data rows per second\n",
    "    * there can't be any default for playback_rate that is meaningful with every data\n",
    "        * when the argument is specified the DataPlayer will not consider any timestamp information\n",
    "        * when the argument is not specified the DataPlayer will look for timestamp information in the data\n",
    "            * `df['timestamp']` by default\n",
    "            * `DataPlayer(son, df, timestamp_key='time')`\n",
    "                * this way we can override the default timestamp lookup key\n",
    "                \n",
    "\n",
    "The DataPlayer object could also register **multiple sonification objects**, so that we could have more modular design, e.g. use separate sonifications for the smile and for the eyebrows and play them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_video(df_row):\n",
    "    # update videoframe\n",
    "    pass\n",
    "\n",
    "dp.add_callback('update_video', update_video)\n",
    "# dp.del_callback('update_video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it useful we have to allow the registration of callbacks also during initialization (and in other moments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real-time sonification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control the data playback by using the **widget interface** or by using the **following methods**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.play()\n",
    "# dp.play(rate=2)\n",
    "# dp.play(rate=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.seek(frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.seektime(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus other possible navigation functions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method would record what is currently being played.\n",
    "* NOTE: maybe its not a good idea to call the class DataPlayer if it allows recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.record_start('recording.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.record_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the relationship between record_stop and the navigation methods? Should they be independent or not?\n",
    "* pause\n",
    "* stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record for 10 second (the recording stops automatically)\n",
    "dp.record_start('recording.wav', duration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non real-time sonification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can render the NRT sonification using the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.export('sonification.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe export is not the best name:\n",
    "* render\n",
    "* nrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamz (https://streamz.readthedocs.io/en/latest/core.html) seems to add only microsecond overhead to normal Python operations.\n",
    "* there should not be any performance issues using it\n",
    "* maybe we don't really need the library and we can write easier code without it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could write a mainloop where read live data and input it into the RTDataPlayer, but this would block the main thread. This is a problem because we would want to interact programmatically with the RTDataPlayer later on.\n",
    "\n",
    "It is better to encapsulate this in a method and run it in a separate thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acquisition of live feature is too dependent on the context to code it all in advance. The mainloop code should be specified by the user. We could pass a function at object creation time, but it's clearer if we define RTDataPlayer as an abstract base class and we instantiate custom subclasses of it. E.g. in NamedPipeDataPlayer the data player would read data from a specified named pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedPipeDataPlayer(ps.RTDataPlayer):\n",
    "    \n",
    "    def data_loop(self, fifo_path):\n",
    "        # open a named pipe and parse the data in the expected format        \n",
    "        with open(fifo_path, 'r') as fifo:\n",
    "            # the reader attempts to execute fifo.readline() (which is blocking if there are no lines)\n",
    "            reader = csv.reader(fifo)\n",
    "\n",
    "            # the loop ends when the pipe is closed from the writing side\n",
    "            for row in reader:\n",
    "                # input data the read row in the streamz Stream object\n",
    "                self.source.emit(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rtdp = NamedPipeDataPlayer(son)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the flow of data\n",
    "rtdp.listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record live sounds as with the DataPlayer\n",
    "rtdp.record_start('recording.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log real-time data with the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp.log_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_stop can maybe return a DataPlayer object to be able to perform the playback of the logged data immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdp.log_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "* It is not clear which are the responsabilities of the objects, e.g. DataPlayers allow recording\n",
    "    * change its name?\n",
    "* How to write sonification logic only once?\n",
    "    * row sonification function could return a bundle, so that the routing part (to the server or to a score file through NRT) would be handled by the framework\n",
    "* RTDataPlayer can be hard to understand, even if the method should be flexible\n",
    "* Jupyter notebook widgets are able to support all these operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVC based\n",
    "* Model: SonificationModel (OnlineDataModel, OfflineDataModel)\n",
    "* View: OnlineView, OfflineView\n",
    "* Controller: OfflineController, OnlineController\n",
    "\n",
    "This seems to be a standard and easily understandable design, but I don't know if it is a good idea to apply it in a jupyter notebook environment:\n",
    "* the programmatic interaction could become more complex\n",
    "    * should we also force the programmatic interaction through the controller?\n",
    "    * the MVC is usually used in different contexts, where the only interaction happens through the GUI\n",
    "* in a jupyter notebook we could have various sonifications rendered through widgets and plug only one at a time in the DataPlayer\n",
    "    * usually the view is conceived as a monolithic entity, which means that we should render the sonification widget together with the playback widget. This would make the everything less pluginable and flexible, e.g. we have to re-render all the view if we change the sonification\n",
    "        * is it actually a problem?\n",
    "* A MVC architecture applied in a context where it does not fit well (i.e. where the user of the framework has other expectations) could generate a lot of confusion.\n",
    "    * maybe it would be better to adopt a completely different structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonification, DataProcessor, RTDataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution is kind of similar to Thomas' one.\n",
    "\n",
    "* Sonification as in the first example\n",
    "* DataProcessor - coordinates the following elements:\n",
    "    * Sonification\n",
    "    * OfflineData (does not necessairly have to be an object)\n",
    "    * DataPlayer\n",
    "* RTDataProcessor - coordinates the following elements:\n",
    "    * Sonification\n",
    "    * OnlineData (does not necessairly have to be an object)\n",
    "        * we can leverage streamz and use the emit method on a source (attribute)\n",
    "\n",
    "In the RTDataProcessor we don't need any RTDataPlayer, because there is no navigation and playback to perform. The main tasks of the RTDataProcessor are:\n",
    "* call the sonification on the current element obtained from the stream\n",
    "* log (save) the stream of data\n",
    "* does it makes sense to record the sounds produced by the sonification directly? Surely there must be a way to synchronize it with the logged data... the mechanism should be analogous to the one of DataProcessor.\n",
    "\n",
    "RTDataProcessor can also be used as a builder for DataProcessor (after recording).\n",
    "\n",
    "How can we handle streams of video or audio data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The framework should also contain some objects to simplify the building of the widget interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thomas' idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isfw as sf # import the \"interactive sonification framework\" package as sf \n",
    "import sc3nb as scn\n",
    "scn.startup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts = sf.RTStream() # create a rt stream for sensor data. This needs to be worked out... \n",
    "\n",
    "dp = sf.DataProcessor(source=rts) # create a data processor with data source connected to a rtstream \n",
    "\n",
    "dp.son = sf.PercussiveSon() # this needs to be worked out...., perhaps allow to pass an array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging\n",
    "dp.logfile = \"\" # default None, but if set, logging goes into file, \n",
    "                # if object is a DataFrame, log lines are appended\n",
    "dp.logging = True # default is False, True immediately could immediately start logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the processor\n",
    "dp.run() # this would automatically call self.son.initialize()\n",
    "         # and then for every incoming sensor data vector self.son.update(dp, dp.current_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can enjoy the sonification and perhaps tweak it a bit like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.level += 6 # add 6 dB global volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.mute() # to have silence for discussing with a colleague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.unmute() # to continue listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.running   # should return True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.source = None # disconnect the source, e.g. because we want to continue with recorded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.source = DataPlayer()\n",
    "pl = sf.DataPlayer(dp.data.copy()) # switch to just logged data from previous rt interaction\n",
    "dp.source = pl\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "would give the repr which states something like:<br>\n",
    "```150 frames, avg fps 21.5, dim=18``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.loop(from=80, to=-1) # configure player to loop segment from frame 80 to end\n",
    "pl.cue(frame=80)\n",
    "pl.start() # now we enjoy the sonification in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would like to attend to this in more detail and slow down by a factor of 2\n",
    "pl.rate = 0.5 # the player stretches times between rows by a 1/rate and so the sonification slows down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can work on some sonification parameters, let's for instance shorten the percussive sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.son.anyproperty_available_in_class *= 0.5 # in this case we assume we have a property for event duration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more convenient: create a widget to control a property\n",
    "wdg_1 = sf.parameter_widget(dp.son.anyproperty_available_in_class, (0.1, 1, 100))\n",
    "# in result of which we get a slider widget from 0.1 to 1 in 100 steps \n",
    "# so that we can control the parameter in realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that we need to see the video in parallel, so here we need to synchronize a video playback component with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for coding we stop temporarily the dp\n",
    "dp.pause() \n",
    "# actualy we could let it run but just stop new data from coming int\n",
    "dp.resume(); pl.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's interactively load the data\n",
    "dp.vidview = sf.VideoViewer(\"MyVideo.mp4\", mode=\"memory\") # loading the full video into memory\n",
    "dp.vidview\n",
    "\n",
    "# current doubt: perhaps vidview should not be part of dp but connected to pl? makes more sense...\n",
    "# such are issues to be thought about..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this could output the __repr__(), e.g.:<br>\n",
    "```Video: 18s at 30fps = 540 frames of res 800 x 640 x 3 (RGB)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.vidview.display() # a window pops up showing the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.parameter_widget(dp.vidview.currentframe, (0, dp.vidview.nrframes, 1))\n",
    "# a slider pops up which allows us to browse the video..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets play the video together with the sonification.\n",
    "# as it is already registered as vidview, it would automatically receive the frame number from the pd, so\n",
    "pl.resume() # will present"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
